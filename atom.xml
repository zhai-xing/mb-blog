<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zhai-xing.github.io/mb-blog</id>
    <title>星辰驿站</title>
    <subtitle>=别怕路长梦远，总有星河照耀=</subtitle>
    <icon>https://zhai-xing.github.io/mb-blog/images/favicon.ico</icon>
    <link href="https://zhai-xing.github.io/mb-blog" />
    <author>
      <name>摘星</name>
    </author>
    <updated>2024-08-03T10:48:39.393Z</updated>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/2024/08/03/hello-world/</id>
        <title>Hello World</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/2024/08/03/hello-world/"/>
        <content type="html">&lt;p&gt;Welcome to &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvLw==&#34;&gt;Hexo&lt;/span&gt;! This is your very first post. Check &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv&#34;&gt;documentation&lt;/span&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=&#34;&gt;troubleshooting&lt;/span&gt; or you can ask me on &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==&#34;&gt;GitHub&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#quick-start&#34;&gt;#&lt;/a&gt; Quick Start&lt;/h2&gt;
&lt;h3 id=&#34;create-a-new-post&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#create-a-new-post&#34;&gt;#&lt;/a&gt; Create a new post&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo new &lt;span class=&#34;token string&#34;&gt;&#34;My New Post&#34;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s&#34;&gt;Writing&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;run-server&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#run-server&#34;&gt;#&lt;/a&gt; Run server&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo server&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=&#34;&gt;Server&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;generate-static-files&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#generate-static-files&#34;&gt;#&lt;/a&gt; Generate static files&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo generate&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s&#34;&gt;Generating&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;deploy-to-remote-sites&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#deploy-to-remote-sites&#34;&gt;#&lt;/a&gt; Deploy to remote sites&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo deploy&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvb25lLWNvbW1hbmQtZGVwbG95bWVudC5odG1s&#34;&gt;Deployment&lt;/span&gt;&lt;/p&gt;
</content>
        <updated>2024-08-03T10:48:39.393Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0</id>
        <title>Hadoop集群搭建笔记</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0"/>
        <content type="html">&lt;h1 id=&#34;一-hadoop环境搭建&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#一-hadoop环境搭建&#34;&gt;#&lt;/a&gt; 一、hadoop 环境搭建&lt;/h1&gt;
&lt;h2 id=&#34;1-安装vmware&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-安装vmware&#34;&gt;#&lt;/a&gt; 1、安装 VMware&lt;/h2&gt;
&lt;h2 id=&#34;2-vmware内安装centos&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-vmware内安装centos&#34;&gt;#&lt;/a&gt; 2、VMware 内安装 centos&lt;/h2&gt;
&lt;p&gt;记得在这个地方配置虚拟机网络连接开启&lt;/p&gt;
&lt;p&gt;创建 root 用户的密码为 p@ssw0rd&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906101501464.png&#34; alt=&#34;image-20230906101501464&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;配置虚拟机静态ip&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#配置虚拟机静态ip&#34;&gt;#&lt;/a&gt; 配置虚拟机静态 IP&lt;/h3&gt;
&lt;h2 id=&#34;1设置虚拟机网关&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1设置虚拟机网关&#34;&gt;#&lt;/a&gt; 1. 设置虚拟机网关&lt;/h2&gt;
&lt;p&gt;点击导航栏上面的【编辑】--&amp;gt;【虚拟网络编辑器】，并以【管理员】的身份打开虚拟机。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/20210924085719523.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;点击【VMnet8 NAT 模式】，取消使用本地使用本地&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9zby5jc2RuLm5ldC9zby9zZWFyY2g/cT1kaGNwJmFtcDtzcG09MTAwMS4yMTAxLjMwMDEuNzAyMA==&#34;&gt; dhcp&lt;/span&gt; 服务，配置网络段（子网 ip 段）为 192.168.200.0，点击 NAT 设置&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/20210924085854490.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;上面这个图有点问题，如果要启动多个虚拟机，需要使用本地的 dhcp 需要勾选 在里面配置 ip 地址的可选范围&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906113409191.png&#34; alt=&#34;image-20230906113409191&#34; /&gt;&lt;/p&gt;
&lt;p&gt;我的三台虚拟机分别节点是 100  101 102&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906113443342.png&#34; alt=&#34;image-20230906113443342&#34; /&gt;&lt;/p&gt;
&lt;p&gt;配置【网关 ip】，注意【网关 ip】需要在【子网 ip】段下，这里设置为 192.168.200.2&lt;/p&gt;
&lt;p&gt;不要设置为 192.168.200.1，否则会出错。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/20210924090332795.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;打开命令行，输入【vim /etc/sysconfig/network-scripts/ifcfg-ens33 】，并修改配置文件内容。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/20210924091044120.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;#ip&lt;br /&gt;
IPADDR=192.168.200.200&lt;br /&gt;
NETMASK=255.255.255.0&lt;br /&gt;
#gateway&lt;br /&gt;
GATEWAY=192.168.200.2&lt;br /&gt;
#dns&lt;br /&gt;
DNS1=192.168.200.2&lt;/p&gt;
&lt;p&gt;配置完了后重启一下网络服务&lt;/p&gt;
&lt;p&gt;service network restart&lt;/p&gt;
&lt;p&gt;然后检查一下是否可以 ping 通&lt;/p&gt;
&lt;h2 id=&#34;2-配置克隆虚拟机&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-配置克隆虚拟机&#34;&gt;#&lt;/a&gt; 2. 配置克隆虚拟机&lt;/h2&gt;
&lt;p&gt;克隆出两台虚拟机 分别修改刚刚配置文件中的 ip 地址&lt;/p&gt;
&lt;p&gt;分别启动三台虚拟机 设置其名字&lt;/p&gt;
&lt;p&gt;hostnamectl set-hiostname master (名字)  其他两台设置为 slave1 slave2&lt;/p&gt;
&lt;p&gt;分别修改三台虚拟机 /etc/hosts 文件&lt;/p&gt;
&lt;p&gt;添加如下信息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;192.168.198.100 master
192.168.198.101 slave1
192.168.198.102 slave2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;关闭三台机器的 SeLimux 安全机制&lt;/p&gt;
&lt;p&gt;修改 /etc/sysconfig/selinux 文件&lt;/p&gt;
&lt;p&gt;将 enforcing 改成 disabled&lt;/p&gt;
&lt;h2 id=&#34;3配置ssh免密登录&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3配置ssh免密登录&#34;&gt;#&lt;/a&gt; 3. 配置 ssh 免密登录&lt;/h2&gt;
&lt;p&gt;执行命令 ssh-keygen -t rsa  然后连续三个回车&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://img-blog.csdnimg.cn/6bfb3581602c45b4952461857c12f1ff.png&#34; alt=&#34;在这里插入图片描述&#34; /&gt;&lt;/p&gt;
&lt;p&gt;执行命令 ssh-copy-id root@master 将公钥拷贝到 slavle1&lt;/p&gt;
&lt;p&gt;将命令重复在三台机器上执行， 确保能互相登录&lt;/p&gt;
&lt;h2 id=&#34;3-安装hadoop完全分布式模式&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-安装hadoop完全分布式模式&#34;&gt;#&lt;/a&gt; 3、安装 Hadoop（完全分布式模式）&lt;/h2&gt;
&lt;h3 id=&#34;1安装java环境&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1安装java环境&#34;&gt;#&lt;/a&gt; 1. 安装 Java 环境&lt;/h3&gt;
&lt;p&gt;将 jdk 安装包上传到 opt 目录下&lt;br /&gt;
执行命令解压 tar -zxvf jdk-8u271-linux-x64.tar.gz -C /usr/local&lt;br /&gt;
 修改 /etc/profile 文件&lt;br /&gt;
加入下面的内容&lt;br /&gt;
 export JAVA_HOME=/usr/local/jdk1.8.0_271&lt;br /&gt;
export PATH=&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;J&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;/&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;:&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;JAVA_HOME/bin:&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.09618em;&#34;&gt;J&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;PATH&lt;br /&gt;
export CLASSPATH=.:&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;J&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;/&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;/&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;:&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;JAVA_HOME/lib/dt.jar:&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.09618em;&#34;&gt;J&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05724em;&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;JAVA_HOME/lib/tools.jar&lt;/p&gt;
&lt;p&gt;保存并退出&lt;br /&gt;
使其生效  source /etc/profile&lt;br /&gt;
 目前只安装了 一台机器，但是可以将其分发到其他机器上&lt;/p&gt;
&lt;p&gt;将 jdk 包分发到 master 机器上  修改一下命令 即可分发到 slave2 机器&lt;br /&gt;
 scp -r &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;J&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;@&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;:&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;JAVA_HOME root@master:&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.09618em;&#34;&gt;J&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;JAVA_HOME&lt;/p&gt;
&lt;p&gt;将环境配置文件分发到 master 机器上  同上修改命令 可分发到其他的机器&lt;br /&gt;
 scp /etc/profile root@slave2:/etc&lt;/p&gt;
&lt;p&gt;在其他机器上需要执行命令 source /etc/profile 使配置文件生效&lt;/p&gt;
&lt;h3 id=&#34;2hadoop安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2hadoop安装&#34;&gt;#&lt;/a&gt; 2.hadoop 安装&lt;/h3&gt;
&lt;p&gt;下载安装包 建议使用国内清华镜像&lt;br /&gt;
&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2FwYWNoZS9oYWRvb3AvY29tbW9uL3N0YWJsZS8=&#34;&gt; https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/stable/&lt;/span&gt;&lt;br /&gt;
 将压缩包上传到 /opt 目录&lt;br /&gt;
在 /opt 目录下执行&lt;br /&gt;
 tar -xzvf hadoop-3.3.4.tar.gz -C /usr/local&lt;br /&gt;
 将其解压到 /usr/local 目录下&lt;br /&gt;
修改 /etc/profile 文件环境变量&lt;/p&gt;
&lt;p&gt;export HADOOP_HOME=/usr/local/hadoop-3.3.4&lt;br /&gt;
export PATH=&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;/&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;:&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;HADOOP_HOME/bin:&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;HADOOP_HOME/sbin:$PATH&lt;br /&gt;
export HDFS_NAMENODE_USER=root&lt;br /&gt;
export HDFS_DATANODE_USER=root&lt;br /&gt;
export HDFS_SECONDARYNAMENODE_USER=root&lt;br /&gt;
export YARN_RESOURCEMANAGER_USER=root&lt;br /&gt;
export YARN_NODEMANAGER_USER=root&lt;/p&gt;
&lt;p&gt;如果是 hadoop2.x 不用配置用户 只需要前两行就行&lt;br /&gt;
存盘退出 执行命令 source /etc/profile 让配置生效&lt;/p&gt;
&lt;p&gt;验证环境&lt;br /&gt;
 hadoop version 检查&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906132740114.png&#34; alt=&#34;image-20230906132740114&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;3hadoop集群搭建&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3hadoop集群搭建&#34;&gt;#&lt;/a&gt; 3.Hadoop 集群搭建&lt;/h3&gt;
&lt;h4 id=&#34;1在master-虚拟机上配置hadoop&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1在master-虚拟机上配置hadoop&#34;&gt;#&lt;/a&gt; 1. 在 master 虚拟机上配置 hadoop&lt;/h4&gt;
&lt;h5 id=&#34;1编辑hadoop-envsh配置文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1编辑hadoop-envsh配置文件&#34;&gt;#&lt;/a&gt; 1. 编辑 hadoop-env.sh 配置文件&lt;/h5&gt;
&lt;p&gt;执行命令  cd /usr/local/hadoop-3.3.4/etc/hadoop&lt;br /&gt;
 编辑 hadoop-env.sh 配置文件&lt;br /&gt;
分别是 Java 环境变量 hadoop 环境变量  其实只需要第三条就行前面两条已经配置过了&lt;br /&gt;
 export JAVA_HOME=/usr/local/jdk1.8.0_271&lt;br /&gt;
export HADOOP_HOME=/usr/local/hadoop-3.3.4&lt;br /&gt;
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop&lt;br /&gt;
 使用命令将其生效&lt;br /&gt;
 source &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL2hhZG9vcC1lbnYuc2g=&#34;&gt;hadoop-env.sh&lt;/span&gt;&lt;/p&gt;
&lt;h5 id=&#34;2编辑core-sitexml配置文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2编辑core-sitexml配置文件&#34;&gt;#&lt;/a&gt; 2. 编辑 core-site.xml 配置文件&lt;/h5&gt;
&lt;p&gt;&amp;lt;configuration&amp;gt;&lt;br /&gt;
&amp;lt;!-- 用来指定 hdfs 的老大 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;hdfs://master:9000&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!-- 用来指定 hadoop 运行时产生文件的存放目录 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;/usr/local/hadoop-3.3.4/tmp&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;/configuration&amp;gt;&lt;/p&gt;
&lt;p&gt;因为配置了 ip 地址和主机名的映射 因此配置 hdfs 老大节点可以使用 hdfs://master:9000&lt;br /&gt;
 保存一下&lt;/p&gt;
&lt;h5 id=&#34;3编辑hdfs-sitexml配置文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3编辑hdfs-sitexml配置文件&#34;&gt;#&lt;/a&gt; 3. 编辑 hdfs-site.xml 配置文件&lt;/h5&gt;
&lt;p&gt;&amp;lt;configuration&amp;gt;&lt;br /&gt;
&amp;lt;!-- 设置名称节点的目录 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;/usr/local/hadoop-3.3.4/tmp/namenode&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!-- 设置数据节点的目录 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;/usr/local/hadoop-3.3.4/tmp/datanode&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!-- 设置辅助名称节点 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;master:50090&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!--hdfs web 的地址，默认为 9870，可不配置 --&amp;gt;&lt;br /&gt;
&amp;lt;!-- 注意如果使用 hadoop2，默认为 50070--&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;dfs.namenode.http-address&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;0.0.0.0:9870&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!-- 副本数，默认为 3，可不配置 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!-- 是否启用 hdfs 权限，当值为 false 时，代表关闭 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;dfs.permissions.enabled&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;/configuration&amp;gt;&lt;/p&gt;
&lt;p&gt;可以不用设置名称节点的目录、数据节点的目录以及辅助名称节点&lt;/p&gt;
&lt;h5 id=&#34;4编辑mapreduce配置文件-mapread-sitexml&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4编辑mapreduce配置文件-mapread-sitexml&#34;&gt;#&lt;/a&gt; 4. 编辑 MapReduce 配置文件 mapread-site.xml&lt;/h5&gt;
&lt;p&gt;&amp;lt;configuration&amp;gt;&lt;br /&gt;
&amp;lt;!-- 配置 MR 资源调度框架 YARN--&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;yarn.app.mapreduce.am.env&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;HADOOP_MAPRED_HOME=&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;/&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;/&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;/&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;{HADOOP_HOME}&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.map.env&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;HADOOP_MAPRED_HOME=&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.83333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.5782em;vertical-align:-0.0391em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.5782em;vertical-align:-0.0391em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.80952em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.5782em;vertical-align:-0.0391em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.5782em;vertical-align:-0.0391em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.5782em;vertical-align:-0.0391em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.73354em;vertical-align:-0.0391em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.83333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.00773em;&#34;&gt;R&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;{HADOOP_HOME}&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;mapreduce.reduce.env&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;/configuration&amp;gt;&lt;br /&gt;
 后三个属性如果不设置，在运行 hadoop 自带示例的词频统计时会报错&lt;/p&gt;
&lt;h5 id=&#34;5-编辑yarn-sitexml配置文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-编辑yarn-sitexml配置文件&#34;&gt;#&lt;/a&gt; 5、编辑 yarn-site.xml 配置文件&lt;/h5&gt;
&lt;p&gt;&amp;lt;configuration&amp;gt;&lt;br /&gt;
&amp;lt;!-- 配置资源管理器：集群 master--&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;master&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!-- 配置节点管理器上运行的附加服务 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;!-- 关闭虚拟内存检测，在虚拟机环境中不做配置会报错 --&amp;gt;&lt;br /&gt;
&amp;lt;property&amp;gt;&lt;br /&gt;
&amp;lt;name&amp;gt;yarn.nodemanager.vmem-check-enabled&amp;lt;/name&amp;gt;&lt;br /&gt;
&amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;&lt;br /&gt;
&amp;lt;/property&amp;gt;&lt;br /&gt;
&amp;lt;/configuration&amp;gt;&lt;/p&gt;
&lt;h5 id=&#34;6-编辑workers文件确定数据节点&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-编辑workers文件确定数据节点&#34;&gt;#&lt;/a&gt; 6. 编辑 workers 文件确定数据节点&lt;/h5&gt;
&lt;p&gt;在 hadoop2.x 里配置 slaves 文件 在 hadoop3.x 里配置 workers 文件&lt;br /&gt;
通过 workers 文件定义数据节点，根据集群规划三个节点都要作为数据节点&lt;br /&gt;
这样虚拟机集群总共就有 3 个数据节点 正好和副本数配置的 3 一致&lt;/p&gt;
&lt;h4 id=&#34;2在slave1虚拟机上安装hadoop&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2在slave1虚拟机上安装hadoop&#34;&gt;#&lt;/a&gt; 2. 在 slave1 虚拟机上安装 hadoop&lt;/h4&gt;
&lt;p&gt;将 master 虚拟机上的 hadoop 分发到 slave1 虚拟机&lt;br /&gt;
 scp -r &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;@&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;:&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;HADOOP_HOME root@slave1:&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;HADOOP_HOME&lt;br /&gt;
 把配置文件也分发一下&lt;br /&gt;
 scp -r  /etc/profile root@slave1:/etc/profile&lt;/p&gt;
&lt;p&gt;使其配置文件生效 source /etc/profile&lt;/p&gt;
&lt;h4 id=&#34;3在slave2上安装hadoop&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3在slave2上安装hadoop&#34;&gt;#&lt;/a&gt; 3. 在 slave2 上安装 hadoop&lt;/h4&gt;
&lt;p&gt;将 master 虚拟机上的 hadoop 分发到 slave1 虚拟机&lt;br /&gt;
 scp -r &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;@&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;:&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;HADOOP_HOME root@slave1:&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.32833099999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.08125em;&#34;&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10903em;&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;HADOOP_HOME&lt;br /&gt;
 把配置文件也分发一下&lt;br /&gt;
 scp -r  /etc/profile root@slave1:/etc/profile&lt;/p&gt;
&lt;p&gt;使其配置文件生效 source /etc/profile&lt;/p&gt;
&lt;h4 id=&#34;4格式化文件系统&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4格式化文件系统&#34;&gt;#&lt;/a&gt; 4. 格式化文件系统&lt;/h4&gt;
&lt;p&gt;初次启动 HDFS 集群时 必须对主节点进行格式化处理&lt;br /&gt;
执行命令 hdfs namenode -format&lt;br /&gt;
 在 master 节点中输入命令即可&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906143921417.png&#34; alt=&#34;image-20230906143921417&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;5-启动和关闭hadoop集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-启动和关闭hadoop集群&#34;&gt;#&lt;/a&gt; 5. 启动和关闭 Hadoop 集群&lt;/h4&gt;
&lt;h5 id=&#34;1在主节点上启动hadoop集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1在主节点上启动hadoop集群&#34;&gt;#&lt;/a&gt; 1. 在主节点上启动 hadoop 集群&lt;/h5&gt;
&lt;p&gt;执行命令 &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3N0YXJ0LWFsbC5zaA==&#34;&gt;start-all.sh&lt;/span&gt;  一起启动 hdfs 和 yarn 服务&lt;/p&gt;
&lt;h5 id=&#34;2验证是否启动成功&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2验证是否启动成功&#34;&gt;#&lt;/a&gt; 2. 验证是否启动成功&lt;/h5&gt;
&lt;p&gt;在主节点上使用 jps 命令 查看启动进程&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906150348512.png&#34; alt=&#34;image-20230906150348512&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在 slave1 和 slave2 上使用 jps 命令查看&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906150252090.png&#34; alt=&#34;image-20230906150252090&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;3在主节点上停止hadoop集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3在主节点上停止hadoop集群&#34;&gt;#&lt;/a&gt; 3. 在主节点上停止 hadoop 集群&lt;/h5&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3N0b3AtYWxsLnNo&#34;&gt;stop-all.sh&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906151213865.png&#34; alt=&#34;image-20230906151213865&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;3hadoop集群测试&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3hadoop集群测试&#34;&gt;#&lt;/a&gt; 3.Hadoop 集群测试&lt;/h3&gt;
&lt;p&gt;启动 Hadoop 集群后 默认开放了两个端口 9870 和 8088 分别用于监控 HDFS 和 YARN 集群，通过 UI 界面可以方便进行集群的管理和查看 2 和 3 端口有区别  访问前记得关闭防火墙端口&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906181502670.png&#34; alt=&#34;image-20230906181502670&#34; /&gt;&lt;/p&gt;
&lt;p&gt;部署成功 三个节点&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230906183522000.png&#34; alt=&#34;image-20230906183522000&#34; /&gt;&lt;/p&gt;
</content>
        <category term="大数据" scheme="https://zhai-xing.github.io/mb-blog/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" />
        <category term="大数据" scheme="https://zhai-xing.github.io/mb-blog/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" />
        <category term="Hadoop" scheme="https://zhai-xing.github.io/mb-blog/tags/Hadoop/" />
        <updated>2023-09-07T15:49:26.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0</id>
        <title>Redis学习笔记</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"/>
        <content type="html">&lt;h1 id=&#34;一-redis数据类型篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#一-redis数据类型篇&#34;&gt;#&lt;/a&gt; 一、redis 数据类型篇&lt;/h1&gt;
&lt;p&gt;rdis 常见的数据类型及应用场景&lt;/p&gt;
&lt;h4 id=&#34;string&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#string&#34;&gt;#&lt;/a&gt; String&lt;/h4&gt;
&lt;p&gt;String 是最基本的 key-value 结构，key 是唯一标识 value 是具体的值 value 不仅是字符串，还可以是数字 (整数或者浮点数) value 最多可以容纳的数据长度是 512M，&lt;/p&gt;
&lt;h5 id=&#34;内部实现&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内部实现&#34;&gt;#&lt;/a&gt; 内部实现：&lt;/h5&gt;
&lt;p&gt;String 底层实现的数据结构是 int 和 SDS (简单动态字符串)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SDS 不仅可以保存文本数据还可以保存二进制数据，SDS 使用了 len 属性来判断字符串是否结束，&lt;/li&gt;
&lt;li&gt;SDS 获取字符串长度的时间复杂度是 O1&lt;/li&gt;
&lt;li&gt;Redis 的 SDS api 是安全的，拼接字符前会判断空间是否满足要求，不满足会自动扩容，所以不好导致缓冲区溢出&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;常用场景&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#常用场景&#34;&gt;#&lt;/a&gt; 常用场景：&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;常规计数：计算点赞、转发、库存数量、阅读量&lt;/li&gt;
&lt;li&gt;分布式： 使用命令不存在此键就插入成功，而解锁 就是删除键，解锁的额操作需要判断，使用需要保证原子性操作，可以使用 Lua 脚本&lt;/li&gt;
&lt;li&gt;共享 Session 使用 Session 来保存用户的会话状态。&lt;/li&gt;
&lt;li&gt;热点数据缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;list&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#list&#34;&gt;#&lt;/a&gt; List&lt;/h4&gt;
&lt;p&gt;list 是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 添加元素，列最大长度为 2^32-1&lt;/p&gt;
&lt;h5 id=&#34;内部实现-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内部实现-2&#34;&gt;#&lt;/a&gt; 内部实现&lt;/h5&gt;
&lt;p&gt;在 3.2 版本之前内部是采用双向链表或者压缩列表实现的，在后面就只用 quicklist 实现，替代了双向链表和压缩列表&lt;/p&gt;
&lt;h5 id=&#34;常用场景-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#常用场景-2&#34;&gt;#&lt;/a&gt; 常用场景&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;消息队列 ：如果要实现消息队列，需要实现消息的保序、可靠、处理重复的消息&lt;br /&gt;
保序的话，List 本身就是先进先出，已经是有序的了，并且 redis 提供了 BRPOP 命令，称为阻塞式读取，客户端在没有读到 redis 数据时自动阻塞，直到有数据了在读取。 处理重复消息，需要自己生成一个全局 ID，需要记录已经处理过的消息 ID. 而在消息可靠性方面，redis 在用户读取消息后就不会保存，若消费者消费失败消息就丢失了， 对于这个问题，可以再开一个消息队列，作为备份暂存，消费成功后再去删除掉备份的即可。&lt;br /&gt;
存在的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;无法支持消费者组&lt;/li&gt;
&lt;li&gt;无法支持多个消费者消费同一个消息&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;hash&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hash&#34;&gt;#&lt;/a&gt; Hash&lt;/h4&gt;
&lt;p&gt;Hash 是一个键值对集合，其中 value=[{field1,value1},{fieldN,valueN}]&lt;/p&gt;
&lt;h5 id=&#34;内部实现-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内部实现-3&#34;&gt;#&lt;/a&gt; 内部实现&lt;/h5&gt;
&lt;p&gt;hash 类型的底层数据结构采用的是压缩列表或哈希表 。如果 hash 类型的元素格式小于 512 个 并且值小于 64 字节， 就使用压缩列表，反之则使用 hash 表 而在 redis7.0 中，压缩列表数据结构被废弃了，就采用 listpack 来实现&lt;/p&gt;
&lt;h5 id=&#34;使用场景&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#使用场景&#34;&gt;#&lt;/a&gt; 使用场景&lt;/h5&gt;
&lt;p&gt;通常用来缓存一些对象的属性，例如用户信息、购物车（用户 Id，商品 id，数量）&lt;/p&gt;
&lt;h4 id=&#34;set&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#set&#34;&gt;#&lt;/a&gt; Set&lt;/h4&gt;
&lt;p&gt;set 类型是无序唯一的键值集合，他的存储顺序不会按照插入的先后来存储，一个集合最多可存储 2^32-1 个元素，可以进行并交差集运算，也可以支持多个集合去交集、并集、差集。&lt;/p&gt;
&lt;h5 id=&#34;应用场景&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#应用场景&#34;&gt;#&lt;/a&gt; 应用场景&lt;/h5&gt;
&lt;p&gt;Set 类型比较适合用来做数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、并集、补集，当我们存储的数据是无序且需要去重的情况下，比较适合使用集合类型来存储。需要注意 set 的集合计算复杂度较高，在数据量大的情况下，直接执行这些计算会导致 Redis 实例阻塞，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;点赞记录：一个用户只能对一篇文章点赞&lt;/li&gt;
&lt;li&gt;共同关注 ：交集&lt;/li&gt;
&lt;li&gt;抽奖活动：防止重复中奖&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;zset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#zset&#34;&gt;#&lt;/a&gt; Zset&lt;/h4&gt;
&lt;p&gt;zset 相比较与 set 类型多了一个排序属性，score 分值。对于有序集合 zset 每个存储元素相当于是有两个值组成，一个是有序集合的元素值，一个是排序值，&lt;/p&gt;
&lt;h5 id=&#34;内部实现-4&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#内部实现-4&#34;&gt;#&lt;/a&gt; 内部实现&lt;/h5&gt;
&lt;p&gt;内部采用了压缩列表或跳表实现的，若有有序集合元素个数小于 128 个。并且每个元素值小于 64 字节。redis 会使用压缩列表，否则则使用跳表。在 redis7.0 中跳表废弃了使用了 listpack 数据结构来实现&lt;/p&gt;
&lt;h5 id=&#34;应用场景-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#应用场景-2&#34;&gt;#&lt;/a&gt; 应用场景&lt;/h5&gt;
&lt;p&gt;排行榜、电话姓名、有序排列&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;高级数据类型&lt;/p&gt;
&lt;h4 id=&#34;bitmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#bitmap&#34;&gt;#&lt;/a&gt; BitMap&lt;/h4&gt;
&lt;p&gt;位图，是一串连续的二进制数组 [0,1] 可以通过 offset 定位元素，BitMap 通过最小的单位 bit 来进行 0|1 的设置，表示某个元素的值或状态，时间复杂度为 O1,&lt;/p&gt;
&lt;p&gt;内部实现：本身利用了 String 作为底层数据结构，String 会保存为二进制的字节数组，redis 就把每个 bit 位利用起来，用来表示一个元素的二进制状态。&lt;/p&gt;
&lt;p&gt;应用场景：&lt;br /&gt;
签到打卡，判断用户登录状态 连续前端用户数，&lt;/p&gt;
&lt;h4 id=&#34;hyperloglog&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hyperloglog&#34;&gt;#&lt;/a&gt; HyperLogLog&lt;/h4&gt;
&lt;p&gt;是一种用于统计基数的数据集合类型，基数统计是指统计一个集合中不重复元素个数， HyperLoglog 的统计规则是基于概率完成的，不是非常准确，而 HyperLogLog 的优点在于，输入元素的数量或体积很大时，计算基数所需要的内存空间是固定且很小的。&lt;br /&gt;
应用场景： 百万级 UV 网页计数&lt;/p&gt;
&lt;h4 id=&#34;geo&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#geo&#34;&gt;#&lt;/a&gt; GEO&lt;/h4&gt;
&lt;p&gt;这个是用于存储地理位置信息的，并可以对存储的信息进行计算操作，例如搜索附近的餐馆，打车等等。&lt;br /&gt;
内部原理：&lt;br /&gt;
底层采用了 Sorted Set 集合类型，GEO 类型使用了 GOEhash 编码方法实现了经纬度到 sorted set 中元素权重分数的转换，其中的两个关键机制计算对二维地图做区间划分和对区间进行编码。一组经纬度落在某个区间后，就用区间的编码值来标识。&lt;/p&gt;
&lt;h4 id=&#34;stream&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#stream&#34;&gt;#&lt;/a&gt; Stream&lt;/h4&gt;
&lt;p&gt;redis5. 新增的消息队列数据类型，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息保序：XADD/XREAD&lt;/li&gt;
&lt;li&gt;阻塞读取：XREAD block&lt;/li&gt;
&lt;li&gt;重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；&lt;/li&gt;
&lt;li&gt;消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；&lt;/li&gt;
&lt;li&gt;支持消费组形式消费数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;二-redis数据结构篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二-redis数据结构篇&#34;&gt;#&lt;/a&gt; 二、Redis 数据结构篇&lt;/h1&gt;
&lt;p&gt;redis 本身就是一个键值型的数据结构&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225928934.png&#34; alt=&#34;image-20230905225928934&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向 dict 结构的指针。&lt;/li&gt;
&lt;li&gt;dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用哈希表 1，哈希表 2 再 rehash 的时候才会使用&lt;/li&gt;
&lt;li&gt;dictht 结构表示哈希表的结构，结构体存放了哈希表数组，每个数组都指向应该哈希表节点的结构体指针 dictEntry 结构，表示哈希表节点的结构，结构里存放了 **void * key 和 void * value 指针， key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225939660.png&#34; alt=&#34;image-20230905225939660&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sds&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#sds&#34;&gt;#&lt;/a&gt; SDS&lt;/h3&gt;
&lt;p&gt;redis 是使用 C 语言实现的，但是他没有直接使用 C 语言的 char* 字符数组，而是自己封装了一个名为简单动态字符串的数据结构，来表示字符串， 也就是 SDS&lt;br /&gt;
 不使用 c 语言的默认字符数组是因为:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;C 语言默认的字符数组是以 \0 表示结束的，在二进制数据中经常有 \0 这样的数据串，使用就不能保存&lt;/li&gt;
&lt;li&gt;C 语言的字符串是不会记录自身的缓冲区大小的。容易发生溢出&lt;/li&gt;
&lt;li&gt;字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225948684.png&#34; alt=&#34;image-20230905225948684&#34; /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;SDS 的自动扩容机制 如果所需要的长度小于 1mb 。那么是翻倍扩容，如果超过 1Mb 是按照 newlen=1mb&lt;/li&gt;
&lt;li&gt;flags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，这 5 种类型的主要区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同。
&lt;ul&gt;
&lt;li&gt;sdshdr16 类型的 len 和 alloc 的数据类型都是 uint16_t，表示字符数组长度和分配空间大小不能超过 2 的 16 次方。&lt;/li&gt;
&lt;li&gt;sdshdr32 则都是 uint32_t，表示表示字符数组长度和分配空间大小不能超过 2 的 32 次方。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;链表&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#链表&#34;&gt;#&lt;/a&gt; 链表&lt;/h3&gt;
&lt;p&gt;redis 的链表结构很简单，就前置节点，后置节点，数据；但是封装了一个 List 数据结构&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct list &amp;#123;
    //链表头节点
    listNode *head;
    //链表尾节点
    listNode *tail;
    //节点值复制函数
    void *(*dup)(void *ptr);
    //节点值释放函数
    void (*free)(void *ptr);
    //节点值比较函数
    int (*match)(void *ptr, void *key);
    //链表节点数量
    unsigned long len;
&amp;#125; list;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230013442.png&#34; alt=&#34;image-20230905230013442&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ListNode 链表节点的结构里设置有 prev 和 next，获取某个节点的前置节点或后置节点的时间复杂度只需要 O (1)；&lt;/li&gt;
&lt;li&gt;listl 因为有表头指针和标为指针，所以获取表头和表尾节点的时间复杂度是 O (1)&lt;/li&gt;
&lt;li&gt;list 结构因为提供了链表节点数量 len，所以获取链表中的节点数量的时间复杂度只需 O (1)；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;压缩列表&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#压缩列表&#34;&gt;#&lt;/a&gt; 压缩列表&lt;/h3&gt;
&lt;p&gt;压缩列表的最大特点就是他被设计成一种内存紧凑型的数据结构，占用的是一块连续的内存空间，不仅可以利用 CPU 缓存，而且可以针对不同的长度的数据进行相应编码，这种方式可以有效的节省内存开销。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230025692.png&#34; alt=&#34;image-20230905230025692&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;zlbytes 记录整个压缩列表占用内存对内存字节数&lt;/li&gt;
&lt;li&gt;zltail 记录压缩列表尾部节点距离起始地址由多少字节，也就是列尾偏移量，&lt;/li&gt;
&lt;li&gt;zllen：记录压缩列表包含的节点数量&lt;/li&gt;
&lt;li&gt;zlend: 标记压缩列表的结束点 1&lt;/li&gt;
&lt;li&gt;压缩列表查找表头和表尾元素很快，只需要 O (1) 但是查找其他元素就没那么快了，因此压缩列表不适合保存过多元素&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;哈希表&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#哈希表&#34;&gt;#&lt;/a&gt; 哈希表&lt;/h3&gt;
&lt;p&gt;哈希表是一种保存键值对（key-value）的数据结构。&lt;br /&gt;
哈希表中的每一个 key 都是独一无二的，程序可以根据 key 查找到与之关联的 value，或者通过 key 来更新 value，又或者根据 key 来删除整个 key-value 等等。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230038715.png&#34; alt=&#34;image-20230905230038715&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;redis 采用了链式哈希的方式来解决冲突，&lt;/li&gt;
&lt;li&gt;不过，链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O (n)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随着链表越来越长，hash 的查找速度也就会降低，redis 这里提供了 rehash 也就是上面提到的。&lt;/p&gt;
&lt;h4 id=&#34;rehash&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#rehash&#34;&gt;#&lt;/a&gt; rehash&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230048637.png&#34; alt=&#34;image-20230905230048637&#34; /&gt;&lt;br /&gt;
 其实整个备份就是来做数据迁移了，节点太多 hash 桶太少，需要扩容&lt;br /&gt;
 - 随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；&lt;/li&gt;
&lt;li&gt;将「哈希表 1 」的数据迁移到「哈希表 2」 中；&lt;/li&gt;
&lt;li&gt;迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备&lt;/li&gt;
&lt;li&gt;为了避免在 rehash 在数据迁移是，因为拷贝数据导致 redis 性能下降，所以都是采用的渐进式 hash，迁移工作是分多次完成，&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;触发 rehash 时机：&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230059484.png&#34; alt=&#34;image-20230905230059484&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。&lt;/li&gt;
&lt;li&gt;当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;整数集合&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#整数集合&#34;&gt;#&lt;/a&gt; 整数集合&lt;/h3&gt;
&lt;p&gt;整数集合是 Set 对象的底层实现之一，当一个 Set 对象只包含整数值元素，并且元素数量不大时，就用整数集这个数据结构作为底层实现之一，整数集合本质上是一块连续的内存空间吗，整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性&lt;/p&gt;
&lt;h3 id=&#34;跳表&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#跳表&#34;&gt;#&lt;/a&gt; 跳表&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230108527.png&#34; alt=&#34;image-20230905230108527&#34; /&gt;&lt;br /&gt;
 链表在查找元素的时候，因为需要逐一查找，所以查找效率非常低下，时间复杂度是 O (n) ，跳表是链表的改进版&lt;br /&gt;
，多层有序链表，redis 中只有 Zset 用到了跳表，，个人感觉应该是基于链表的二分查找，redis 为什么使用跳表，而不使用红黑树来实现有序集合。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有序集合主要是有增、删、改、查四个操作，这些操作红黑树和跳表时间复杂度都是一样的&lt;/li&gt;
&lt;li&gt;但是基于区间的查询，红黑树的效率就太低了，所以使用跳表&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;quicklist&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#quicklist&#34;&gt;#&lt;/a&gt; quickList&lt;/h3&gt;
&lt;p&gt;quicklist 其实是双向链表和压缩列表的组合，一个 quicklist 就是一个链表，而链表中每个元素又是一个压缩列表，&lt;br /&gt;
压缩列表的不足，如果保存的元素太多，或者元素变大，压缩列表会有连锁更新的情况，quicklist 解决办法，通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230119103.png&#34; alt=&#34;image-20230905230119103&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;listpack&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#listpack&#34;&gt;#&lt;/a&gt; listpack&lt;/h3&gt;
&lt;p&gt;是为了解决压缩列表出现的连锁更新问题，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230130155.png&#34; alt=&#34;image-20230905230130155&#34; /&gt;&lt;br /&gt;
listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。&lt;/p&gt;
&lt;h1 id=&#34;三-reids-持久化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#三-reids-持久化&#34;&gt;#&lt;/a&gt; 三、Reids 持久化&lt;/h1&gt;
&lt;h2 id=&#34;aof持久化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#aof持久化&#34;&gt;#&lt;/a&gt; AOF 持久化&lt;/h2&gt;
&lt;p&gt;redis 每执行一条写操作，就把该命令，以追加的方式写入到一个文件，然后后重启 redis 时，先去读这个这个文件里的命令并执行&lt;br /&gt;
配置文件中开启&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;appendonly yes
appendfilename &amp;quot;appendonly.aof&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230142284.png&#34; alt=&#34;image-20230905230142284&#34; /&gt;&lt;br /&gt;
 写入数据到数据库和写 aof 日志都是在主进程中完成的，有一定性能损失。当然 redis 也提供了其他的写回机制，可以配置，在 redis .conf 中配置 appendfsync&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；&lt;/li&gt;
&lt;li&gt;Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；&lt;/li&gt;
&lt;li&gt;No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230149806.png&#34; alt=&#34;image-20230905230149806&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;aof重写机制&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#aof重写机制&#34;&gt;#&lt;/a&gt; AOF 重写机制&lt;/h4&gt;
&lt;p&gt;AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。Redis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。&lt;br /&gt;
redis 的重写机制是在后方子进程 bgrewriteaof 来完成的，&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230157631.png&#34; alt=&#34;image-20230905230157631&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;rdb持久化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#rdb持久化&#34;&gt;#&lt;/a&gt; RDB 持久化&lt;/h2&gt;
&lt;p&gt;RDB 是内存快照，就是记录一个瞬间的东西，记录的是实时数据，与 AOF 不同，AOF 记录的是命令操作日志，而不是实际的数据。在回复数据时，RDB 要快一些，只需要将 RDB 文件读入内存就可以了，不需要像 AOF 一样还需要执行额外的操作命令。&lt;/p&gt;
&lt;h3 id=&#34;如何生成rdb&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#如何生成rdb&#34;&gt;#&lt;/a&gt; 如何生成 RDB&lt;/h3&gt;
&lt;p&gt;redis 提供了两个命令，分别是 save 和 bgsave，执行了 save 命令会在主线程上生成 rdb 文件，如果写入 rdb 文件太多会阻塞主线程。执行 bgsave 是创建了一个进程来生成 rdb 文件，这样可以避免主线程阻塞。&lt;br /&gt;
也可以通过配置文件的选项，每隔一段时间自动执行 bgsave 命令，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;执行快照是 redis 的数据是可以继续呗修改的，因为采用了写时复制技术，&lt;br /&gt;
执行 bgsave 命令的时候，会通过 fork () 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建  子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个。共享的内存当另一部分被用户修改时，因为采用了写时复制，所以做复制功能的线程也会被同步。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;混合持久化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#混合持久化&#34;&gt;#&lt;/a&gt; 混合持久化&lt;/h2&gt;
&lt;p&gt;尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握：&lt;/p&gt;
&lt;p&gt;如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失；&lt;br /&gt;
如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。&lt;br /&gt;
这是 redis4.0 提出来的，在配置文件中开启&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aof-use-rdb-preamble yes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。&lt;/p&gt;
&lt;h1 id=&#34;功能篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#功能篇&#34;&gt;#&lt;/a&gt; 功能篇&lt;/h1&gt;
&lt;h3 id=&#34;过期删除策略&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#过期删除策略&#34;&gt;#&lt;/a&gt; 过期删除策略&lt;/h3&gt;
&lt;h5 id=&#34;定时删除&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#定时删除&#34;&gt;#&lt;/a&gt; 定时删除&lt;/h5&gt;
&lt;p&gt;在设置 key 的过期时间时，同时创建一个定时事件，当到达时，由事件处理器执行 key 的删除操作&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：内存可以被尽快地释放。定时删除对内存是最友好的。&lt;/li&gt;
&lt;li&gt;缺点：定时删除策略对 CPU 不友好，删除过期 key 可能会占用相当一部分 CPU 时间，CPU 紧张的情况下将 CPU 用于删除和当前任务无关的过期键上，会对服务器的响应时间和吞吐量造成影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;惰性删除&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#惰性删除&#34;&gt;#&lt;/a&gt; 惰性删除&lt;/h5&gt;
&lt;p&gt;不主动删除过期健，每次从数据库访问 key 时检查是否过期，过期则删除，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;优点：只会使用很少的系统资源，对 CPU 最友好。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缺点：如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放。惰性删除策略对内存不友好。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;定期删除&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#定期删除&#34;&gt;#&lt;/a&gt; 定期删除&lt;/h5&gt;
&lt;p&gt;每隔段时间随机从数据库中取出一定数量的 key 进行检查，并删除其中过期的 key&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。&lt;/li&gt;
&lt;li&gt;缺点：内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。难以确定删除操作执行的时长和频率&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;定期删除惰性删除配合使用&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#定期删除惰性删除配合使用&#34;&gt;#&lt;/a&gt; 定期删除 + 惰性删除配合使用&lt;/h5&gt;
&lt;p&gt;redis 选择的时惰性删除 + 定期删除，配合使用，&lt;br /&gt;
Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果过期，则删除该 key，然后返回 null 客户端；&lt;/li&gt;
&lt;li&gt;如果没有过期，不做任何处理，然后返回正常的键值对给客户端&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从过期字典中随机抽取 20 个 key；检查这 20 个 key 是否过期，并删除已过期的 key；已过期 key 的数量占比随机抽取 key 的数量大于 25%，则继续重复步骤直到比重小于 25%。&lt;/p&gt;
&lt;h3 id=&#34;redis-事务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis-事务&#34;&gt;#&lt;/a&gt; redis 事务&lt;/h3&gt;
&lt;p&gt;严格来说 redis 事务只是个批处理，有隔离性但是没有原子性&lt;br /&gt;
 Multi：开启事务&lt;br /&gt;
 Exec：执行&lt;br /&gt;
 Discard: 不执行&lt;br /&gt;
 redis 和 lus 脚本可以进行整合 (用到再学)&lt;/p&gt;
&lt;h3 id=&#34;redis的持久化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis的持久化&#34;&gt;#&lt;/a&gt; redis 的持久化&lt;/h3&gt;
&lt;p&gt;redis 是 nosql 数据库，需要把数据保存到磁盘。&lt;br /&gt;
redis 所有的数据都是保存在内存中，保存的数据量取决于内存的容量。&lt;br /&gt;
redis 提供了两种持久化机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;RDB: 默认开启，快照模式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AOF：日志存储，把对 redis 的操作的命令以日志方式存储到文件，当需要恢复数据时，从头到尾把命令执行一遍， 需要手动开启，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;注：如果同时开启了 RBD 和 AOF 默认是使用 aof 恢复数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rdb默认使用&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#rdb默认使用&#34;&gt;#&lt;/a&gt; RDB（默认使用）&lt;/h4&gt;
&lt;p&gt;RDB 方式是通过快照（ snapshotting ）完成的，当符合一定条件时 Redis 会自动将内存中的数据进行，快照并持久化到硬盘&lt;br /&gt;
执行时机：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;符合指定配置的快照规则&lt;/li&gt;
&lt;li&gt;执行 save 或 bgsave 命令 save 主线程去快照 bgsave 调用异步线程去快照&lt;br /&gt;
主线程是单线程 4.0 I/O 操作 已经有多线程概念&lt;/li&gt;
&lt;li&gt;执行 flushall 或 flushdb&lt;/li&gt;
&lt;li&gt;执行主从复制操作&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可以手动控制快照规则&lt;br /&gt;
 save 多少秒内 数据变了多少&lt;br /&gt;
 save “” : 不使用 RDB 存储&lt;br /&gt;
 save 900 1 ： 表示 15 分钟（900 秒钟）内至少 1 个键被更改则进行快照。&lt;br /&gt;
save 300 10 ： 表示 5 分钟（300 秒）内至少 10 个键被更改则进行快照。&lt;br /&gt;
save 60 10000 ：表示 1 分钟内至少 10000 个键被更改则进行快照。&lt;/p&gt;
&lt;p&gt;快照过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;redis 调用系统中的 fork 函数复制一份当前进程的副本（子进程）&lt;/li&gt;
&lt;li&gt;父进程继续接收客户端的发来的命令，而子进程则开始将内存中的数据写入到硬盘中的临时文件，&lt;/li&gt;
&lt;li&gt;当子进程写完所有的数据后，会用临时文件替换掉旧的 rdb 文件，至此一次快照完成。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;rdb 的优缺点&lt;br /&gt;
优点：&lt;br /&gt;
RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进&lt;br /&gt;
程，然后这个子进程就会处理接下来的所有保存工作，父进程无需执行任何磁盘 I/O 操作.&lt;/p&gt;
&lt;p&gt;缺点：使用 RDB 方式实现持久化，一旦 Redis 异常退出，就会丢失最后一次快照以后更改的所有数据，如果数据集比较大的时候， fork 可以能比较耗时，造成服务器在一段时间内停&lt;br /&gt;
止处理客户端的请求；&lt;/p&gt;
&lt;h4 id=&#34;aof&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#aof&#34;&gt;#&lt;/a&gt; AOF&lt;/h4&gt;
&lt;p&gt;默认情况下 Redis 没有开启 AOF （ append only file ）方式的持久化。&lt;br /&gt;
开启 AOF 持久化后，每执行一条会更改 Redis 中的数据的命令， Redis 就会将该命令写入硬盘中的 AOF 文件，这一过程会降低 Redis 的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高 AOF 的性能。&lt;br /&gt;
Redis 每次更改数据的时候， aof 机制都会将命令记录到 aof 文件，但是实际上由于操作系统的缓存机制，数据并没有实时写入到硬盘，而是进入硬盘缓存。再通过硬盘缓存机制去刷新到保存到文件。&lt;/p&gt;
&lt;h4 id=&#34;混合持久化方式&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#混合持久化方式&#34;&gt;#&lt;/a&gt; 混合持久化方式&lt;/h4&gt;
&lt;p&gt;这是在 4.0 之后的新版本中新增的。混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。&lt;br /&gt;
有两种开启方式：&lt;br /&gt;
1、通过命令行开启；&lt;br /&gt;
2、通过配置文件开启&lt;/p&gt;
&lt;h2 id=&#34;redis-集群模式&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis-集群模式&#34;&gt;#&lt;/a&gt; Redis 集群模式&lt;/h2&gt;
&lt;h3 id=&#34;主从复制&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#主从复制&#34;&gt;#&lt;/a&gt; 主从复制&lt;/h3&gt;
&lt;h3 id=&#34;哨兵集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#哨兵集群&#34;&gt;#&lt;/a&gt; 哨兵集群&lt;/h3&gt;
&lt;h3 id=&#34;redis-cluster-集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis-cluster-集群&#34;&gt;#&lt;/a&gt; Redis Cluster 集群&lt;/h3&gt;
&lt;h4 id=&#34;集群介绍&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#集群介绍&#34;&gt;#&lt;/a&gt; 集群介绍&lt;/h4&gt;
&lt;h5 id=&#34;1-搭建主从&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-搭建主从&#34;&gt;#&lt;/a&gt; 1、搭建主从&lt;/h5&gt;
&lt;p&gt;主节点：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;port 8001
daemonize no
protected-mode no
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;1-搭建分片集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-搭建分片集群&#34;&gt;#&lt;/a&gt; 1、搭建分片集群&lt;/h5&gt;
&lt;p&gt;测试是在一台服务器上同时启动多个 redis 实例完成的，当然也可以使用多个服务器目前条件有限，&lt;br /&gt;
1）先下载安装一台单机的 redis&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;安装 GCC 环境&lt;br /&gt;
 yum install -y gcc-c++&lt;br /&gt;
yum install -y wget&lt;/li&gt;
&lt;li&gt;下载并解压缩 Redis 源码压缩包&lt;br /&gt;
 wget &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL2Rvd25sb2FkLnJlZGlzLmlvL3JlbGVhc2VzL3JlZGlzLTUuMC40LnRhci5neg==&#34;&gt;http://download.redis.io/releases/redis-5.0.4.tar.gz&lt;/span&gt;&lt;br /&gt;
tar -zxf redis-5.0.4.tar.gz&lt;br /&gt;
3. 编译原码&lt;br /&gt;
 cd redis-5.0.4&lt;br /&gt;
make&lt;br /&gt;
4. 安装 Redis ，需要通过 PREFIX 指定安装路径，如果不指定默认是安装到 /usr/lcoal/bin 启动的适合不太方便&lt;br /&gt;
 make install PREFIX=/kkb/server/redis&lt;br /&gt;
 这步做完最好把安装包里面的 redis.conf 文件复制一份到安装目录下的 bin 目录中，这样启动就方便很多&lt;br /&gt;
 5. 修改配置文件参数&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# 将`daemonize`由`no`改为`yes`
daemonize yes
# 默认绑定的是回环地址，默认不能被其他机器访问
# bind 127.0.0.1
# 是否开启保护模式，由yes该为no
protected-mode no
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;6. 启动服务&lt;br /&gt;
./redis-server redis.conf&lt;br /&gt;
7. 关闭服务&lt;br /&gt;
./redis-cli shutdown&lt;br /&gt;
 这样单机就搭建完成了。下面是集群&lt;/p&gt;
&lt;p&gt;2）将 bin 目录下的数据持久化文件删掉，在启动集群前要保证是一台全新的 redis. 只保留以下 7 个文件&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230250244.png&#34; alt=&#34;image-20230905230250244&#34; /&gt;&lt;br /&gt;
3) 将 bin 目录复制 6 份，分别命名 1-6，修改每个目录里面的 redi-conf 文件，将端口号分别改为 8801-8806&lt;br /&gt;
 将配置文件中的 设置为此 cluster-enable yes&lt;br /&gt;
 另外需要关闭防火墙，或者设置白名单，开启端口等等。不然多个服务器之间集群无法访问&lt;/p&gt;
&lt;p&gt;4） 启动所有的 redis，我这里写了一个脚本启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd bin-1
chmod 777 redis-server
./redis-server redis.conf
cd ..
cd bin-2
chmod 777 redis-server
./redis-server redis.conf
cd ..
cd bin-3
chmod 777 redis-server
./redis-server redis.conf
cd ..
cd bin-4
chmod 777 redis-server
./redis-server redis.conf
cd ..
cd bin-5
chmod 777 redis-server
./redis-server redis.conf
cd ..
cd bin-6
chmod 777 redis-server
./redis-server redis.conf
cd ..
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;5）进入 bin-1 中，使用以下命令，创建集群&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; ./redis-cli --cluster create 192.168.1.110:8001 192.168.1.110:8002 192.168.1.110:8003 192.168.1.110:8004 192.168.1.110:8005 192.168.1.110:8006 --cluster-replicas 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后的参数 1 表示 每个 redis 有一个备份 当主机挂了，备份定上，这也是为什么需要 6 个的原因，&lt;br /&gt;
6) 如下图，在过程中输入 yes 启动成功&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230303127.png&#34; alt=&#34;image-20230905230303127&#34; /&gt;&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230310340.png&#34; alt=&#34;image-20230905230310340&#34; /&gt;&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230318236.png&#34; alt=&#34;image-20230905230318236&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;2-连接集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-连接集群&#34;&gt;#&lt;/a&gt; 2、连接集群&lt;/h4&gt;
&lt;p&gt;连接集群中任意一台机器都行，例如使用 cli 连接 8001 机器&lt;br /&gt;
./redis-cli -h 192.168.1.110 -p 8001 -c&lt;br /&gt;
 连接集群一定要加 - c 这个参数，不然插入会报错，因为集群模式下，每次新增键都需要进行插槽计算。如果用可视化也是需要集群模式连接&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230325571.png&#34; alt=&#34;image-20230905230325571&#34; /&gt;&lt;br /&gt;
 使用 Java 去连接时，需要将所以的节点列出来，然后他会自己去选择连接&lt;/p&gt;
&lt;h4 id=&#34;3-查看集群状态&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-查看集群状态&#34;&gt;#&lt;/a&gt; 3、查看集群状态&lt;/h4&gt;
&lt;h4 id=&#34;4-集群优缺点&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-集群优缺点&#34;&gt;#&lt;/a&gt; 4、集群优缺点&lt;/h4&gt;
&lt;p&gt;客户端与 Redis 节点直连，不需要中间 Proxy 层，直接连接任意一个 Master 节点&lt;br /&gt;
根据公式 HASH_SLOT=CRC16 (key) mod 16384，计算出映射到哪个分片上，然后 Redis 会去相应的节&lt;br /&gt;
点进行操作&lt;br /&gt;
优点:&lt;br /&gt;
(1) 无需 Sentinel 哨兵监控，如果 Master 挂了，Redis Cluster 内部自动将 Slave 切换 Master&lt;br /&gt;
 (2) 可以进行水平扩容&lt;br /&gt;
 (3) 支持自动化迁移，当出现某个 Slave 宕机了，那么就只有 Master 了，这时候的高可用性就无法很好的保证&lt;br /&gt;
了，万一 Master 也宕机了，咋办呢？ 针对这种情况，如果说其他 Master 有多余的 Slave ，集群自动把多余&lt;br /&gt;
的 Slave 迁移到没有 Slave 的 Master 中。&lt;br /&gt;
缺点:&lt;br /&gt;
(1) 批量操作是个坑&lt;br /&gt;
 (2) 资源隔离性较差，容易出现相互影响的情况。&lt;/p&gt;
&lt;h2 id=&#34;redis数据存储细节&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis数据存储细节&#34;&gt;#&lt;/a&gt; redis 数据存储细节&lt;/h2&gt;
&lt;p&gt;redis 的一个 DB 就是一个 HashTable,&lt;br /&gt;
 一个 hashtable 由 1 个 dict 结构、2 个 dictht 结构、1 个 dictEntry 指针数组（称为 bucket）和多个 dictEntry 结构组成&lt;br /&gt;
 dictEntry 结构用于保存键值对，结构定义如下：&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230336488.png&#34; alt=&#34;image-20230905230336488&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;redis的对象类型与内存编码&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis的对象类型与内存编码&#34;&gt;#&lt;/a&gt; redis 的对象类型与内存编码&lt;/h4&gt;
&lt;p&gt;Redis 支持 5 种对象类型，而每种结构都有至少两种编码&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;String&lt;br /&gt;
 字符串是最基础的类型，因为所有的键都是字符串类型，且字符串之外的其他几种复杂类型的元素也是字符串&lt;br /&gt;
字符串长度不能超过 512MB。有三种编码 分别是 int ;embstr ;raw; 数据比较少时使用 embstr 数据比较多时使用 raw&lt;br /&gt;
key-value&lt;br /&gt;
SDS 结构体进行存储&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;List&lt;br /&gt;
 列表（list）用来存储多个有序的字符串，每个字符串称为元素；&lt;br /&gt;
一个列表可以存储 2^64-1 个元素。&lt;br /&gt;
Redis 中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。&lt;br /&gt;
Redis3.0 之前列表的内部编码可以是压缩列表（ziplist）或双端链表（linkedlist）但是在 3.2 版本之后 因为转换也 是个费时且复杂的操作，引入了一种新的数据格式，结合了双向列表 linkedlist 和 ziplist 的特点，称之为 quicklist。有 的节点都用 quicklist 存储，省去了到临界条件是的格式转换。&lt;br /&gt;
压缩列表（ziplist）是 Redis 为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结&lt;br /&gt;
构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值，放到一个连续内存区。当一个列表只包含少量列表项时，并且每个列表项时小整数值或短字符串，那么 Redis 会使用压缩列表来做该列表的底层实现，&lt;br /&gt;
 目前使用的是 quicklist 我们仍旧可以将其看作一个双向列表，但是列表的每个节点都是一个 ziplist，其实就是&lt;br /&gt;
 linkedlist 和 ziplist 的结合。quicklist 中的每个节点 ziplist 都能够存储多个数据元素。&lt;br /&gt;
Redis3.2 开始，列表采用 quicklist 进行编码。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230344677.png&#34; alt=&#34;image-20230905230344677&#34; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hash&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Redis 中内层的哈希既可能使用哈希表，也可能使用压缩列表。&lt;/li&gt;
&lt;li&gt;只有同时满足下面两个条件时，才会使用压缩列表：&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;哈希中元素数量小于 512 个；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;哈希中所有键值对的键和值字符串长度都小于 64 字节。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set&lt;br /&gt;
 但集合与列表有两点不同：集合中的元素是无序的，因此不能通过索引来操作元素；集合中的元素不能有重复。&lt;br /&gt;
intSet: 集合中的元素都是数值类型&lt;br /&gt;
只有同时满足下面两个条件时，集合才会使用整数集合：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;集合中元素数量小于 512 个；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;集合中所有元素都是整数值。&lt;br /&gt;
如果有一个条件不满足，则使用哈希表；且编码只可能由整数集合转化为哈希表，反方向则不可能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ZSet&lt;br /&gt;
 有序集合的内部编码可以是压缩列表（ziplist）或跳跃表（skiplist）。&lt;br /&gt;
只有同时满足下面两个条件时，才会使用压缩列表：&lt;br /&gt;
1）有序集合中元素数量小于 128 个；&lt;br /&gt;
2）有序集合中 所有成员长度都不足 64 字节 。&lt;br /&gt;
如果有一个条件不满足，则使用跳跃表；且编码只可能由压缩列表转化为跳跃表，反方向则不可能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;跳表-zskiplist&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#跳表-zskiplist&#34;&gt;#&lt;/a&gt; 跳表 zskiplist：&lt;/h4&gt;
&lt;p&gt;类似于折半查找&lt;/p&gt;
&lt;h2 id=&#34;redis性能优化简单学了点&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis性能优化简单学了点&#34;&gt;#&lt;/a&gt; redis 性能优化（简单学了点）&lt;/h2&gt;
&lt;h3 id=&#34;优化内存占用&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#优化内存占用&#34;&gt;#&lt;/a&gt; 优化内存占用&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;利用 jemalloc 内存分配器（默认使用）&lt;/li&gt;
&lt;li&gt;能用整形 / 长整型的尽量使用，减少使用字符串&lt;/li&gt;
&lt;li&gt;利用共享对象，引用常量池&lt;/li&gt;
&lt;li&gt;缩短键值对的存储长度（减少 key 的长度）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;性能优化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#性能优化&#34;&gt;#&lt;/a&gt; 性能优化&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;设置键值的过期时间&lt;/li&gt;
&lt;li&gt;使用 lazy free 特性，（惰性删除），不是马上删掉，而是放到删除队列里面，一起删除，或者是开子线程删除。&lt;/li&gt;
&lt;li&gt;限制 redis 内存大小，设置内存淘汰策略&lt;/li&gt;
&lt;li&gt;禁用长耗时的查询命令&lt;/li&gt;
&lt;li&gt;使用 slowlog 优化耗时命令&lt;/li&gt;
&lt;li&gt;避免大量数据同时失效&lt;/li&gt;
&lt;li&gt;使用 Pipeline 批量操作数据&lt;/li&gt;
&lt;li&gt;客户端使用连接池优化&lt;/li&gt;
&lt;li&gt;使用分布式架构来增加读写速度&lt;/li&gt;
&lt;li&gt;禁用 THP 特性 /*&lt;/li&gt;
&lt;/ol&gt;
</content>
        <category term="Redis" scheme="https://zhai-xing.github.io/mb-blog/categories/Redis/" />
        <category term="原理" scheme="https://zhai-xing.github.io/mb-blog/tags/%E5%8E%9F%E7%90%86/" />
        <category term="学习笔记" scheme="https://zhai-xing.github.io/mb-blog/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" />
        <updated>2023-09-05T14:57:10.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/MySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0</id>
        <title>MySQL学习笔记</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/MySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"/>
        <content type="html">&lt;h1 id=&#34;一-mysql基础篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#一-mysql基础篇&#34;&gt;#&lt;/a&gt; 一、 Mysql 基础篇&lt;/h1&gt;
&lt;h4 id=&#34;语句执行流程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#语句执行流程&#34;&gt;#&lt;/a&gt; 语句执行流程&lt;/h4&gt;
&lt;h5 id=&#34;mysql查询语句执行流程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysql查询语句执行流程&#34;&gt;#&lt;/a&gt; mysql 查询语句执行流程：&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;建立连接：这里需要验证身份和权限&lt;/li&gt;
&lt;li&gt;查询缓存 (如果有缓存则直接返回缓存数据，如果木有则进行下一步，需要注意，如果有增删改操作会清除掉缓存)&lt;/li&gt;
&lt;li&gt;解析器：先做词法分析、再做语法分析 (注：表不存在或者字段不存在，并不是在解析器)&lt;/li&gt;
&lt;li&gt;执行器： 执行器有三个阶段，预处理阶段、优化阶段、执行阶段&lt;/li&gt;
&lt;li&gt;返回数据&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;词法分析主要是识别关键字构成语法树，这样方便后面的模块得到关键字、表名&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;语法分析主要是分析语法是否正确&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预处理阶段：检查表名、列名是否存在 将 * 号换成所有列&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优化阶段：优化器主要是将 sql 语句的执行计划确定下来，例如索引的选择、&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;执行阶段：执行器就会和存储引擎交互了，交互是以记录为单位的。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225131183.png&#34; alt=&#34;image-20230905225131183&#34; /&gt;&lt;br /&gt;
mysql 更新语句执行流程：&lt;br /&gt;
更新语句同样需要走一次查询数据的流程，但数据的更新是在存储引擎中做的，在本文中存储引擎选择的是 Innodb。更新流程需要有日志的辅助，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重做日志: redo Log 是物理日志，记录了某个数据页做了什么修改，每当执行一个事务就会产生一条或者多条物理日志。&lt;mark&gt;事务提交时&lt;/mark&gt;，先将 redo log 持久化到磁盘即可。并且 redo 是可重用的，也就是说空间大小是可设置的，从头开始写，写到末尾又回到开头写， redo log 解决了事务中的持久性。这里到了一个 WAL 技术，&lt;br /&gt;
&lt;mark&gt;WAL 技术指的是，MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。&lt;/mark&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;回滚日志: undo log 是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。&lt;br /&gt;
&lt;mark&gt;每开始一个事务都会分配一个 undo 空间，在事务没提交之前 Innodb 会先记录更新前的数据到 undo log 中&lt;/mark&gt;，当需要执行回滚时 就执行一条相反的操作。undo log 有两个参数：roll_pointer 指针和一个 trx_id 事务 id，通过 trx_id 可以知道该记录是被哪个事务修改的；通过 roll_pointer 指针可以将这些 undo log 串成一个链表，形成版本链。&lt;br /&gt;
&lt;mark&gt;当事务提交后 相关的 undo 日志记录会被标记为 &amp;quot;已提交&amp;quot;，这些已提交的 undo 日志记录会在后续的清理过程中被回收和删除&lt;/mark&gt;&lt;br /&gt;
&lt;mark&gt;实现事务回滚，保障事务的原子性：如果出现了错误或者用户执行了 ROLLBACK 语句，可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。&lt;/mark&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;归档日志 ：Server 层生成的日志，主要用于数据备份和主从复制。binlog 是 server 层的日志，不同的存储引擎都可用， 而上面两个是 innoDB 独有的，在完成一条更新操作后，Server 层会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写入 binlog 文件。binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作。&lt;br /&gt;
1. 执行器负责具体执行，会调用存储引擎的接口，通过索引获取到要操作的数据的记录&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;执行器得到聚簇索引记录后 会查看更新前和更新后的数据是否一致，如果一致就不执行。&lt;/li&gt;
&lt;li&gt;开启事务，innodb 在执行操作前需要先开启事务，InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来&lt;/li&gt;
&lt;li&gt;innodb 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了&lt;/li&gt;
&lt;li&gt;至此一条记录更新完成了&lt;/li&gt;
&lt;li&gt;在一条更新语句执行完成后，然后开始记录该语句对应的 binlog&lt;/li&gt;
&lt;li&gt;事务提交，事务提交分为两个阶段
&lt;ul&gt;
&lt;li&gt;prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；&lt;/li&gt;
&lt;li&gt;commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；&lt;br /&gt;
8. 至此，一条更新语句执行完成。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;二-日志篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二-日志篇&#34;&gt;#&lt;/a&gt; 二、日志篇&lt;/h1&gt;
&lt;p&gt;mysql 日志文件分为三种:&lt;/p&gt;
&lt;h3 id=&#34;undo-log-回滚日志&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#undo-log-回滚日志&#34;&gt;#&lt;/a&gt; undo log 回滚日志&lt;/h3&gt;
&lt;p&gt;回滚日志是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要是用于事务回滚和 MVCC, 考虑一个问题，一个事务在执行过程中还没有提交事务，mysql 发生了崩溃，就需要 undo log 来回滚到事务之前的数据去。&lt;br /&gt;
undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225157734.png&#34; alt=&#34;image-20230905225157734&#34; /&gt;&lt;br /&gt;
 原理：&lt;br /&gt;
每当 innodb 引擎对一条记录进行操作时，要把回滚时需要的信息都记录到 undolog 里，发生回滚时就读取 undolog 的数据，做相反操作。不同的操作，记录的内容也不一样&lt;br /&gt;
另外 undolog +readview 实现了 MVCC：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于读提交隔离级别是在每个 select 都会生成一个新的 read view 也意味着事务期间多次读取同一个数据 前后两次读的数据可能会出现不一致，因为另外一个事务修改了记录并提交了&lt;/li&gt;
&lt;li&gt;对于可重复读级别，是启动事务时生成了一个 read view 然后整个事务期间都在用整个 read view 这样就保证了事务期间读到的数据都是事务启动前的记录。&lt;br /&gt;
&lt;mark&gt;undo log 和数据页的刷盘策略是一样的，都需要通过 redo log 保证持久化。&lt;/mark&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;redo-log-重做日志&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redo-log-重做日志&#34;&gt;#&lt;/a&gt; redo log 重做日志&lt;/h3&gt;
&lt;p&gt;为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候 innodb 引擎会先更新内存，然后将本次对整个页的修改以 redolog 的形式记录下来，就算更新完成了，后续 innodb 会在适当的时候由后台线程将缓存在 BufferPool 的脏页刷新到磁盘，这就是 WAL 技术，WAL 技术是指 MYSQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写入到磁盘&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;redolog 有自己的内存缓存，&lt;/li&gt;
&lt;li&gt;redolog 有刷盘机制可手动配置&lt;/li&gt;
&lt;li&gt;InnoDB 存储引擎有 1 个重做日志文件组 ( redo log Group） 是一个文件组写完了可以循环写，防止丢失&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;undo和-redo的区别&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#undo和-redo的区别&#34;&gt;#&lt;/a&gt; undo 和 redo 的区别&lt;/h4&gt;
&lt;p&gt;这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：&lt;br /&gt;
redo log 记录了此次事务「完成后」的数据状态，记录的是更新之后的值；&lt;br /&gt;
undo log 记录了此次事务「开始前」的数据状态，记录的是更新之前的值；&lt;br /&gt;
&lt;mark&gt;事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，&lt;/mark&gt;&lt;/p&gt;
&lt;h3 id=&#34;binglog-归档日志&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#binglog-归档日志&#34;&gt;#&lt;/a&gt; binglog 归档日志&lt;/h3&gt;
&lt;p&gt;binglog 主要是做备份和主从复制的，并且 binglog 是 server 层的日志，是全量日志，&lt;br /&gt;
而前面俩都是 Innodb 的日志，换一个存储引擎就没有了。binlog 是追加写，一个文件写满了就创建一个新的继续写，不会覆盖日志，但是 redolog 会覆盖，&lt;br /&gt;
binglog 日志有三种格式&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;StateNet: 每一条修改数据的 sql 都会被记录到 binlog 中，，主从复制时，可以直接运行语句复现，STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；&lt;/li&gt;
&lt;li&gt;row：记录行数据最终被修改的样子，&lt;br /&gt;
4.mixed 包含了 statement 和 row 模式，会根据不同情况自动使用上面的两种日志&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;三-mysql事务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#三-mysql事务&#34;&gt;#&lt;/a&gt; 三、MySQL 事务&lt;/h1&gt;
&lt;p&gt;插入一条数据发生了什么？&lt;br /&gt;
使用 Innodb 引擎时执行增删改操作时，会自动在 Innodb 引擎层开启事务。&lt;br /&gt;
ACID&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原子性：事务最小工作单元，要么全成功，要么全失败（重做日志了实现的）&lt;/li&gt;
&lt;li&gt;一致性：事务开始和结束后，数据库的完整性不会被破坏&lt;/li&gt;
&lt;li&gt;隔离性：不同事务之间互不影响，（是通过 MVCC 来实现的）
&lt;ol&gt;
&lt;li&gt;读未提交 RU：一个事务读取到另一个事务未提交的数据。（会出现脏读）&lt;/li&gt;
&lt;li&gt;读已提交（RC)：一个事务读取到另一个事务已经提交的数据，（会出现不可重复读，同一个 sql 语句在一个事务里面读到的数据不一致）&lt;/li&gt;
&lt;li&gt;可重复读 (RR)：一个事务只能读到另一个已经提交的事务修改的数据（会出现幻读，一个事务因读取到另一个事务已提交的 insert 数据或者 dlete 数据，导致对同一张表读取两次以上的结果不一致。查询结果是多条记录时，才有可能出现幻读。）&lt;/li&gt;
&lt;li&gt;串行化：&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;持久性：事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失。（回滚日志来实现的）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;并行事务会引发什么问题&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#并行事务会引发什么问题&#34;&gt;#&lt;/a&gt; 并行事务会引发什么问题&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;脏读：一个事务读到了另一个未提交事务修改过的数据&lt;/li&gt;
&lt;li&gt;不可重复读：一个事务内两次读取数据出现不一致的情况，&lt;/li&gt;
&lt;li&gt;幻读：在一个事务内多次查询某个符合查询条件的记录数量，如果出现前后两次查询到的记录数量不一致，就是幻读。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;事务与mvcc底层原理详解&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#事务与mvcc底层原理详解&#34;&gt;#&lt;/a&gt; 事务与 MVCC 底层原理详解&lt;/h3&gt;
&lt;p&gt;MVCC 实现了两个事务隔离级别，可重复读和读已提交，MVCC 使数据库读不加锁，提高了数据库的并发处理能力，多版本并发控制仅仅是一种技术理念，没有统一的标准，其核心理念就是快照，不同的事务访问不同版本的数据快照，从而实现不同的事务隔离级别。&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225220682.png&#34; alt=&#34;image-20230905225220682&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;m_ids ：指的是在创建 Read View 时，当前数据库中活跃事务的事务 id 列表，活跃事务指的就是，启动了但还没提交的事务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;min_trx_id ：指的是在创建 Read View 时，当前数据库中活跃事务中事务 id 最小的事务，也就是 m_ids 的最小值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;max_trx_id ：创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;creator_trx_id ：指的是创建该 Read View 的事务的事务 id。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着 (还没提交事务)，所以该版本的记录对当前事务不可见。&lt;/li&gt;
&lt;li&gt;如果记录的 trx_id 不在 m_ids 列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;如何解决幻读&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#如何解决幻读&#34;&gt;#&lt;/a&gt; 如何解决幻读&lt;/h3&gt;
&lt;p&gt;分为快照读和当前读&lt;/p&gt;
&lt;h4 id=&#34;快照读&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#快照读&#34;&gt;#&lt;/a&gt; 快照读&lt;/h4&gt;
&lt;p&gt;通过 MVCC 方式解决幻读，可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一直的。即使中途有其他事务写入了一条数据，也是查不出来的。&lt;br /&gt;
&lt;mark&gt;对于快照读， MVCC 并不能完全避免幻读现象&lt;/mark&gt;。&lt;mark&gt;当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读&lt;/mark&gt;&lt;/p&gt;
&lt;h4 id=&#34;当前读&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#当前读&#34;&gt;#&lt;/a&gt; 当前读&lt;/h4&gt;
&lt;p&gt;通过 next-key lock 方式解决了幻读，因为当执行 select for update 语句的时候会加上 next key lock 如果有其他事务在锁范围内插入了已经语句 这个插入语句就会被阻塞.&lt;/p&gt;
&lt;h4 id=&#34;lbcc-基于锁的并发控制&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#lbcc-基于锁的并发控制&#34;&gt;#&lt;/a&gt; LBCC 基于锁的并发控制。&lt;/h4&gt;
&lt;p&gt;一个事务去读一个数据库的时候就加上锁，不允许其他事务操作&lt;/p&gt;
&lt;h4 id=&#34;innodb的mvcc实现&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#innodb的mvcc实现&#34;&gt;#&lt;/a&gt; Innodb 的 MVCC 实现&lt;/h4&gt;
&lt;p&gt;MVCC 在 mysql 中的实现是依赖的 undo log 和 read view&lt;br /&gt;
MVCC 只支持两种隔离级别 分别是：读已提交，可重复读&lt;br /&gt;
根据不同的行为，undo log 分为两种 insert undo log 和 update undo log&lt;br /&gt;
insert undo log 是在 inser 操作下产生的 undo log&lt;br /&gt;
 因为 insert 操作的记录只对事务本身可见，对于其他事务&lt;/p&gt;
&lt;h4 id=&#34;读提交的实现&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#读提交的实现&#34;&gt;#&lt;/a&gt; 读提交的实现&lt;/h4&gt;
&lt;p&gt;读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View。事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务&lt;/p&gt;
&lt;h1 id=&#34;四-mysq锁篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#四-mysq锁篇&#34;&gt;#&lt;/a&gt; 四、Mysq 锁篇&lt;/h1&gt;
&lt;h3 id=&#34;锁介绍&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#锁介绍&#34;&gt;#&lt;/a&gt; 锁介绍&lt;/h3&gt;
&lt;p&gt;范围分：全局锁，表级锁，行级锁&lt;br /&gt;
根据功能分：共享锁（s)，排他锁 (x)，&lt;br /&gt;
全局锁就是对整个数据库实例枷锁，加锁后整个数据库就处于只读状态，后续的 MDL ，DDL 语句 和已经更新操作的提交语句都将被阻塞，一般应用于数据库全局备份时，保证数据完整性和一致性。&lt;br /&gt;
加锁命令：flush table with read lock;&lt;br /&gt;
 释放锁 unlock tables;&lt;br /&gt;
 一般是在数据库做备份的时候才使用全局锁，但是会带来问题，全局锁会导致数据库在时间内处于只读状态，会导致业务停滞，&lt;br /&gt;
解决方案，如果数据库引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前可先开启事务，会先创建 ReadView 然后整个事务执行期间都在使用这个 ReadView ，而且在可重复读的情况下，即使其他业务更新数据库，也不会有影响。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;表级锁 (server 实现的): 有四种 读锁，写锁，元数据锁&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;表级共享锁：lock table 表名 read;&lt;/li&gt;
&lt;li&gt;表级排他锁: lock table 表名 write&lt;/li&gt;
&lt;li&gt;元数据锁： 在一个事务中对一个表进行查询操作不允许其他会话对表结构进行修改，就在表上加元数据锁&lt;/li&gt;
&lt;li&gt;自增锁：使用自增字段时，使用自增主键保证主键不冲突&lt;/li&gt;
&lt;li&gt;意向锁：当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。&lt;br /&gt;
那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录&lt;br /&gt;
意向锁的目的是为了快速判断表里释放有记录被加锁&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;行级锁&lt;br /&gt;
&lt;strong&gt;要求必须使用 Innodb 引擎&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;记录锁：锁定索引中的一条记录&lt;/li&gt;
&lt;li&gt;间隙锁：要么锁住索引记录中间的值，要么锁住第一个索引记录前面的值或者最后一个索引记录后面的值&lt;/li&gt;
&lt;li&gt;临健锁：是索引记录上的记录锁和在索引记录之前的间隙锁的组合（间隙锁 + 记录锁）&lt;/li&gt;
&lt;li&gt;插入意向锁： 做 insert 操作时添加的对记录 id 的锁&lt;br /&gt;
记录锁：根据主键等值更新时使用记录锁&lt;br /&gt;
共享记录锁: select * from where id=1 lock inshare mode&lt;br /&gt;
 排他记录锁: select * from where id=1 for update;&lt;br /&gt;
 意向锁就是一个标志位，表示当前表中，是否有行锁&lt;br /&gt;
意向锁分为：行锁：S 意向锁：IS; 行锁 X 意向锁：IX&lt;br /&gt;
 间隙锁：仅仅锁住一个索引区间，在记录和记录之间的范围区间就是间隙，间隙锁就是加在区间之上，防止插入数据，目的就是幻读 (读一个范围数据，读到了其他数据插入的数据) 在更新过程中，不仅需要对记录加锁还需要在记录与记录之间加锁，加的就是间隙锁。&lt;br /&gt;
临键锁：就是记录锁 + 间隙锁，是一个左开右闭区间&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;死锁的产生&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#死锁的产生&#34;&gt;#&lt;/a&gt; 死锁的产生&lt;/h3&gt;
&lt;p&gt;有两个会话，互相持有对方所需要的资源。&lt;/p&gt;
&lt;h4 id=&#34;如何避免死锁&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#如何避免死锁&#34;&gt;#&lt;/a&gt; 如何避免死锁・&lt;/h4&gt;
&lt;p&gt;1、注意程序逻辑，最常见的就是更新表，程序的更新过程最好意思一致的&lt;br /&gt;
 2、保持事务的轻量，越是轻量的事务，占有越少的锁资源，这样发生死锁的概率就很低了&lt;br /&gt;
 3、提高运行速度，避免使用子查询，尽量使用主键等&lt;br /&gt;
 4、尽快提交事务，减少持有锁的时间，事务越早提交，锁就越早释放。&lt;/p&gt;
&lt;h1 id=&#34;五-索引&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#五-索引&#34;&gt;#&lt;/a&gt; 五、索引&lt;/h1&gt;
&lt;p&gt;什么是索引，帮助快速查找数据的一个数据结构。索引可以说是数据的目录，&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225256269.png&#34; alt=&#34;image-20230905225256269&#34; /&gt;&lt;br /&gt;
 索引分类&lt;br /&gt;
按数据结构来分，可以分为，B + 树索引，Hash 索引，Full-text 索引&lt;br /&gt;
按物理存储分类：聚簇索引 (主键索引)，二级索引 (辅助索引)&lt;br /&gt;
 按字段特性分类： 主键索引、唯一索引、普通索引、前缀索引&lt;br /&gt;
按字段个数分类： 单列索引，联合索引。&lt;br /&gt;
如果有主键，默认会使用主键作为聚簇索引的索引键（key）；&lt;br /&gt;
如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；&lt;br /&gt;
在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；&lt;/p&gt;
&lt;h4 id=&#34;什么时候需要索引&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#什么时候需要索引&#34;&gt;#&lt;/a&gt; 什么时候需要索引：&lt;/h4&gt;
&lt;p&gt;字段有唯一性限制的&lt;br /&gt;
经常用于 where 查询条件的字段，&lt;br /&gt;
经常用于 group by 和 order by 的字段，这样查询的时候就不需要再去做一次排序了，&lt;/p&gt;
&lt;h4 id=&#34;什么时候不需要创建索引&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#什么时候不需要创建索引&#34;&gt;#&lt;/a&gt; 什么时候不需要创建索引&lt;/h4&gt;
&lt;p&gt;字段中有大量重复数据的，比如性别&lt;br /&gt;
表数据很少的时候&lt;br /&gt;
经常更新的字段不需要索引，比如余额&lt;/p&gt;
&lt;h4 id=&#34;优化索引的方法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#优化索引的方法&#34;&gt;#&lt;/a&gt; 优化索引的方法&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前缀索引优化&lt;/strong&gt;&lt;br /&gt;
就是使用某个字段中字符串的前几个字符建立索引，使用前缀索引可以减少索引字段的大小，但是 order by 无法使用前缀索引，无法把前缀索引当做覆盖索引使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;覆盖索引优化&lt;/strong&gt;&lt;br /&gt;
在索引 B + 树的叶子节点上都能找到的那些索引。可以建立联合索引，商品 id 姓名，作为一个联合索引，可以避免回表。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;主键索引最好自增&lt;/strong&gt;&lt;br /&gt;
那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;索引最后设置为 NOT NULL&lt;/strong&gt;&lt;br /&gt;
 如果索引列存在 NULL 会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为 NULL 的行。&lt;br /&gt;
NULL 值是一个没意义的值，但是它会占用物理空间&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;防止索引失效&lt;/strong&gt;&lt;br /&gt;
 1. 当使用左或者左右模糊匹配的时候，也就是 like % xx 或者 like % xx% 这两种方法都会造成索引失效。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当我们在查询条件中对索引列做了计算、函数、类型转换后也会导致失效。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;联合索引要遵循最左匹配原则不然也会失效。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;where 子句中，如果 or 前的条件列是索引，而 or 后的条件不是所有，那么也会导致索引失效。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All（全表扫描）&lt;br /&gt;
index（全索引扫描）&lt;br /&gt;
range（索引范围扫描）&lt;br /&gt;
ref（非唯一索引扫描）&lt;br /&gt;
eq_ref（唯一索引扫描）&lt;br /&gt;
const（结果只有一条的主键或唯一索引扫描）&lt;/p&gt;
&lt;h4 id=&#34;count-是什么&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#count-是什么&#34;&gt;#&lt;/a&gt; count () 是什么？&lt;/h4&gt;
&lt;p&gt;count () 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。&lt;/p&gt;
&lt;h3 id=&#34;索引的数据结构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#索引的数据结构&#34;&gt;#&lt;/a&gt; 索引的数据结构&lt;/h3&gt;
&lt;p&gt;Mysql 的索引数据结构选用的是 B + 树，为什么选用呢？&lt;br /&gt;
索引至少要支持等值查询和范围查询。&lt;/p&gt;
&lt;h4 id=&#34;选择hash表做查询&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#选择hash表做查询&#34;&gt;#&lt;/a&gt; 选择 Hash 表做查询&lt;/h4&gt;
&lt;p&gt;如果是等值查询，hash 的性能是很好的，但是无法做范围查询，空间复杂度较高。&lt;/p&gt;
&lt;h4 id=&#34;二叉查找树&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二叉查找树&#34;&gt;#&lt;/a&gt; 二叉查找树&lt;/h4&gt;
&lt;p&gt;这个是可以做等着查询和范围查询的，但是极端情况下，可能会退化成链表。&lt;/p&gt;
&lt;h4 id=&#34;平衡二叉查找树&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#平衡二叉查找树&#34;&gt;#&lt;/a&gt; 平衡二叉查找树&lt;/h4&gt;
&lt;p&gt;查找的时间复杂度和树的高度有关，树有多高就需要查找多少次，每个节点的读取都对应着一次 IO 操作，在表数据量变大时，树的高度也会变大，查询效率下降严重&lt;br /&gt;
并且平衡二叉查找树，不支持范围快速查找，范围查询时，需要通过根结点多次遍历。查询效率不高&lt;/p&gt;
&lt;h4 id=&#34;b树&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#b树&#34;&gt;#&lt;/a&gt; B 树&lt;/h4&gt;
&lt;p&gt;改造了二叉树，在一个节点上存多个数值，可以将树的高度变矮，降低磁盘的读取 IO;&lt;br /&gt;
B 树是一种多叉平衡查找树&lt;/p&gt;
&lt;p&gt;B 树：非叶子节点和叶子节点都会存储数据。&lt;br /&gt;
b 树缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;B 树不支持范围查询的快速查找，如果我们想要查找 15 和 26 之间的数据，查找到 15 之后，需要回到&lt;br /&gt;
根节点重新遍历查找，需要从根节点进行多次遍历，查询效率有待提高。&lt;/li&gt;
&lt;li&gt;如果 data 存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中可存储的&lt;br /&gt;
数据量就会变少，树相应就会变高，磁盘 IO 次数就会变大&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;b树-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#b树-2&#34;&gt;#&lt;/a&gt; B + 树&lt;/h4&gt;
&lt;p&gt;而 B + 树只在叶子节点上存储数据，且使用链表将叶子节点连接起来。&lt;/p&gt;
&lt;h4 id=&#34;为什么用b树不用b树&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#为什么用b树不用b树&#34;&gt;#&lt;/a&gt; 为什么用 B + 树不用 B 树&lt;/h4&gt;
&lt;p&gt;B + 树相对于 B 树在磁盘 IO 操作上具有优势，尤其适用于范围查询和索引场景&lt;/p&gt;
&lt;p&gt;在进行查询操作时，B 树可能需要在内部节点上进行多次访问才能达到叶子节点，而 B + 树由于只有叶子节点存储数据，所以查询时只需一次访问。&lt;/p&gt;
&lt;h3 id=&#34;mysql索引实现&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysql索引实现&#34;&gt;#&lt;/a&gt; mysql 索引实现&lt;/h3&gt;
&lt;h4 id=&#34;myisam引擎&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#myisam引擎&#34;&gt;#&lt;/a&gt; MyIsam 引擎&lt;/h4&gt;
&lt;p&gt;主键索引实现是使用了 B + 树，MyISAM 在查询时，会将索引节点缓存在 MySQL 缓存中，而数据缓存依赖于操作系统自身的缓存。&lt;/p&gt;
&lt;h4 id=&#34;innodbt引擎&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#innodbt引擎&#34;&gt;#&lt;/a&gt; Innodbt 引擎&lt;/h4&gt;
&lt;p&gt;索引和数据文件是放在一起的，Innodb 引擎要求每张表必须有主键索引，&lt;br /&gt;
每个 InnoDB 表都有一个聚簇索引 ，聚簇索引使用 B + 树构建，叶子节点存储的数据是整行记录。一般&lt;br /&gt;
情况下聚簇索引等同于主键索引，当一个表没有创建主键索引时，InnoDB 会自动创建一个 ROWID 字&lt;br /&gt;
段来构建聚簇索引。&lt;/p&gt;
&lt;p&gt;在使用辅助索引时，数据会回表，除聚簇索引之外的所有索引都称为辅助索引，InnoDB 的辅助索引只会存储主键值而非磁盘地址，&lt;br /&gt;
使用辅助索引需要检索两遍索引：首先检索辅助索引获得主键，然后使用主键到主索引中检索获得记&lt;br /&gt;
录。根据在辅助索引树中获取的主键 id，到主键索引树检索数据的过程称为回表查询。回表会有性能损耗，所以也有说在 Innodb 引擎里使用辅助索引，性能不如 MyIsam 引擎，因为在 Mysaml 里面辅助索引和主索引是相同的。&lt;/p&gt;
&lt;h5 id=&#34;innodb组合索引&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#innodb组合索引&#34;&gt;#&lt;/a&gt; Innodb 组合索引&lt;/h5&gt;
&lt;p&gt;组合索引就是一个字段包含多个索引。&lt;br /&gt;
如何存储的呢，是根据创建索引时的字段先后顺序，假设组合索引是 (a,b,c) , 那么在建立索引存储结构 B + 树时，就先按照 a 字段排序，当 a 字段相同时 ，就按 b 字段排序，当 b 字段相同时，就按 c 字段排序，在写 sql 语句的时候，要按照索引创建的顺序去写条件&lt;/p&gt;
&lt;h5 id=&#34;最左前缀匹配原则&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#最左前缀匹配原则&#34;&gt;#&lt;/a&gt; 最左前缀匹配原则&lt;/h5&gt;
&lt;h4 id=&#34;什么情况下适合建立索引&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#什么情况下适合建立索引&#34;&gt;#&lt;/a&gt; 什么情况下适合建立索引&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;频繁出现在 where 条件 order 排序 group 分组 字段中的列&lt;/li&gt;
&lt;li&gt;select 频繁查询的列，考虑是否创建联合索引&lt;/li&gt;
&lt;li&gt;多表 join 关联查询 ，on 两边的字段都应该创建索引&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;索引优化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#索引优化&#34;&gt;#&lt;/a&gt; 索引优化&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;表记录很少不需创建索引 （索引是要有存储的开销）&lt;/li&gt;
&lt;li&gt;频繁更新的字段不适合创建索引&lt;/li&gt;
&lt;li&gt;区分度低的字段不适合建立索引，例如性别，会导致扫描行数过多，再加上回表查询的消耗。如果使用索引，比全表扫描的性能还要差。这些字段一般会用在组合索引中。&lt;/li&gt;
&lt;li&gt;在 InnoDB 存储引擎中，主键索引建议使用自增的长整型，避免使用很长的字段。&lt;/li&gt;
&lt;li&gt;不建议用无序的值作为索引。例如身份证、UUID，更新数据时会发生频繁的页分裂，页内数据不紧凑，浪费磁盘空间。&lt;/li&gt;
&lt;li&gt;尽量创建组合索引，而不是单列索引，一个组合索引等于多个单列索引&lt;br /&gt;
创建原则：组合索引应该把把频繁的列，区分度高的值放在前面。频繁使用代表索引的利用率高，&lt;br /&gt;
区分度高代表筛选粒度大，可以尽量缩小筛选范围&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;六-架构篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#六-架构篇&#34;&gt;#&lt;/a&gt; 六、架构篇&lt;/h1&gt;
&lt;h4 id=&#34;mysql文件类型&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysql文件类型&#34;&gt;#&lt;/a&gt; mysql 文件类型：&lt;/h4&gt;
&lt;p&gt;日志文件：&lt;br /&gt;
错误日志&lt;br /&gt;
通用日志：默认是关闭的，可以手动开启，，通用查询日志会记录用户所有的操作，&lt;br /&gt;
binlog: 二进制日志，做 Mysql 主从复制时使用&lt;br /&gt;
慢查询日志: mysql 调优时使用，默认关闭，&lt;br /&gt;
数据文件：&lt;br /&gt;
记录表结构、数据、索引信息&lt;br /&gt;
 InnoDB ，MyIsam 等&lt;br /&gt;
不同的存储引擎，生成的文件也不一样&lt;br /&gt;
在文件管理系统中 mysql 的 一个数据库对应一个目录，&lt;br /&gt;
frm 文件类型：表结构定义文件&lt;br /&gt;
 MYD 文件 Mylasm 引擎创建的表，存储表中数据&lt;br /&gt;
 MYI: 文件 Mylasm 引擎创建的表，存储表中索引&lt;br /&gt;
 ibd 文件 InnoDB 引擎创建的表，其中包含表中数据和索引&lt;br /&gt;
 MyIsam 引擎创建的表有三个文件&lt;br /&gt;
 InnoDB 引擎创建的表有两个文件&lt;br /&gt;
同一个数据库中，不同的表可以使用不同的数据引擎，Mysql5.5 开始默认使用 InnoDB 之前是使用的 mylsam，&lt;/p&gt;
&lt;h4 id=&#34;mysql架构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysql架构&#34;&gt;#&lt;/a&gt; MYSQL 架构：&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;大致分为两层:
mysqlServer层: 连接池、优化器、执行器等组件
存储引擎层： Innodb，以及其他引擎，基本可以忽略 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;![](…/…/B69V2_(NQHU5$@Q[S18C9S9%201.png)&lt;br /&gt;
 Mysql8 中缓存被移除了，在 mysql5.7 中依然存在，默认是关闭的，&lt;br /&gt;
缓存的缺点：&lt;br /&gt;
1、需要占用大量的内存空间&lt;br /&gt;
 2、维护缓存需要成本。&lt;br /&gt;
3、命中率不高&lt;br /&gt;
在同一个 sql 语句会反复执行时，可以开启，可以使用命令查看缓存命中率&lt;/p&gt;
&lt;p&gt;分析器：&lt;br /&gt;
先对 sql 进行词法分析，语法分析&lt;br /&gt;
优化器：&lt;br /&gt;
执行器：&lt;/p&gt;
&lt;p&gt;存储引擎&lt;br /&gt;
 Mysql 有多个自带存储引擎，也可以自己去安装第三方的存储引擎，&lt;br /&gt;
使用 show engines 查看 mysql 中自带的存储引擎&lt;br /&gt;
&lt;strong&gt;除非需要用到某些 Innodb 不具备的特性，并且没有其他办法可以替代，否则都应该选择 Innodb 引擎&lt;/strong&gt;&lt;br /&gt;
 MEMORY ：内存引擎。把数据和索引全部放到内存中。缺点是，数据库一旦重启，表数据就丢失了，表结构不会丢失；优点速度快，&lt;/p&gt;
&lt;p&gt;Innode 引擎：&lt;br /&gt;
由，内存池，后台线程，磁盘文件三大部分组成，&lt;br /&gt;
内存结构:&lt;br /&gt;
redo log buffer（重做日志缓冲区) 保证 Mysql 数据库完整性的重要组成部分&lt;br /&gt;
 buffer poll 缓冲池&lt;br /&gt;
数据页缓存&lt;br /&gt;
索引页缓存&lt;br /&gt;
 change buffer 修改缓冲区（插入缓冲区），修改数据之后需要更新辅助索引，为了提高性能暂时先不更新，把要更新的操作放到缓冲区（change buffer）中。&lt;br /&gt;
自适应哈希索引：完全由 mysql 管理，无法人工干预，&lt;br /&gt;
磁盘结构：&lt;br /&gt;
1・系统表空间：ibdata1&lt;br /&gt;
 数据字典&lt;br /&gt;
双写缓冲区&lt;br /&gt;
修改缓冲区，内存中的 changebuffer 的映射&lt;br /&gt;
回滚段，undolog&lt;br /&gt;
2、用户表空间（每个表一个）&lt;br /&gt;
默认情况下，每个表都对应一个 ibd 文件，就是用户表空间，用户的数据和索引都保存在用户表空间中&lt;br /&gt;
 3、通用表空间&lt;br /&gt;
默认没有这个文件的，在 mysql 中，使用 create tablespace 命令创建的表空间就通用表空间。&lt;br /&gt;
4、回滚表空间&lt;br /&gt;
默认是没有的，undo tablespace 默认是在系统表空间中，&lt;br /&gt;
5、临时表空间，&lt;br /&gt;
默认也是没有的，当使用临时表时才出现。&lt;br /&gt;
6、redolog 重做日志文件&lt;br /&gt;
就是 mysql 数据库数据完整性的重要保障文件。&lt;br /&gt;
由一组文件组成：&lt;br /&gt;
ib logfile0&lt;br /&gt;
iblogfile1&lt;br /&gt;
 两个文件循环使用，文件不会增长。&lt;/p&gt;
&lt;h2 id=&#34;二-innodb架构组织&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二-innodb架构组织&#34;&gt;#&lt;/a&gt; 二、Innodb 架构组织&lt;/h2&gt;
&lt;h3 id=&#34;innodb磁盘文件结构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#innodb磁盘文件结构&#34;&gt;#&lt;/a&gt; Innodb 磁盘文件结构&lt;/h3&gt;
&lt;p&gt;InnoDB 的主要的磁盘文件主要分为三大块：一是系统表空间，二是用户表空间，三是 redo 日志文件和归档文件&lt;br /&gt;
三个表空间的区别，redo 是日志：保证 mysql 数据不丢失的重要环节，采用 WAL 顺序写实现，系统表空间和用户表空间采用的就是随机写，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;redolog 文件:&lt;br /&gt;
 由一组文件组成，默认是两个文件:ib_logfile0 和 ib_logfile1, 循环写入，文件 1 写满之后写文件 2，文件 2 写满之后写文件 1，会覆盖之前的内容。&lt;/li&gt;
&lt;li&gt;系统表空间：&lt;br /&gt;
文件中 ibdata1, 这就是系统表空间文件，其中包含&lt;br /&gt;
 1. 数据字典&lt;br /&gt;
 2. 双写缓冲区&lt;br /&gt;
 3. 修改缓冲区&lt;br /&gt;
 4. 回滚日志&lt;/li&gt;
&lt;li&gt;用户表空间：&lt;br /&gt;
默认每个表对应一个表空间文件。*.ibd 文件，是可配置的，由 innodb_file_per_table 参数控制默认是 true. 其中包含表中的数据和索引信息。&lt;br /&gt;
用户表空间结构：&lt;br /&gt;
ibd 表空间文件&lt;br /&gt;
分段： 段下面分成若干个区，每个区分成若干页（默认 16k）（数据读写以页为单位，页里面存储的数据行，行大小取决于表结构），数据页的大小可以通过参数 innode_page_size 来进行调整；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;而通用表空间和临时表空间用的不多。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225348775.png&#34; alt=&#34;image-20230905225348775&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;1-innodb的内存结构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-innodb的内存结构&#34;&gt;#&lt;/a&gt; 1、Innodb 的内存结构&lt;/h4&gt;
&lt;p&gt;1、redolog buffer ：为了减少磁盘的 io，尽量将 redolog 相关的内容先写到缓冲区中，然后在合适的时机，将缓冲区的数据写到磁盘，合适的时机，就是 commit 操作，在 commit 之前，先把 redologBuffer 中的数据写入到 redolog 文件，如果写入成功那么 commit 成功，如果写入失败则 commit 失败。&lt;br /&gt;
[innodb_flush_log_at_trx_commit] 参数 是 commiit 操作时写 redolog 的行为 ，默认值配置的是 1；&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;属性值 为 0 时，事务提交时，不会对重做日志进行写入操作，而是等待主线程按时写入，每秒写入一次，&lt;/li&gt;
&lt;li&gt;当属性值为 1 时，事务提交时，会将重做日志写入文件系统缓存，并且调用文件系统的 fsync，将文件系统缓冲区的数据真正写入磁盘存储，确保不会出现数据丢失；（fsync 是操作系统的函数）&lt;/li&gt;
&lt;li&gt;当属性值为 2 时，事务提交时，也会将日志文件写入文件系统缓存，但是不会调用文件系统的 fsync , 而是让文件系统直接去判断何时将缓存写入磁盘。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;2-buffer-poll-缓存池&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-buffer-poll-缓存池&#34;&gt;#&lt;/a&gt; 2、Buffer poll 缓存池&lt;/h4&gt;
&lt;p&gt;包含内容，数据页 (16k)，索引页，自适应 hash 索引，双写缓冲区，修改缓冲区（插入缓冲区）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据页：当对数据进行修改时，先把对应的数据页（16k) 放到内存中，然后再进行修改操作，此时内存数据页和磁盘数据页不一致，此时内存的数据页和磁盘的数据页不一致，内存的数据页就形成了脏页，一旦事务提交，就会记录到 redolog，记录了对数据的修改，保证数据安全。当查询数据时，以内存数据为准。&lt;/li&gt;
&lt;li&gt;索引页：一旦向表中插入数据或者修改数据时，把索引页放到内存中，在内存中进行修改，数据安全同样是由 redolog 保证的。&lt;/li&gt;
&lt;li&gt;自适应 hash 索引：Innodb 会根据分为频率和模式，为热点页建立哈希索引，来提高查询效率。不用我们自己维护。&lt;/li&gt;
&lt;li&gt;双写缓冲区：内存数据落盘时，需要使用双写缓冲区。&lt;/li&gt;
&lt;li&gt;修改缓冲区：也叫插入缓冲区，主要是对辅助索引修改时做的一个缓冲，辅助索引就是非主键索引。在早期版本中主要是针对插入操作。在新版本中，修改和删除页进行了缓冲&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;3-内存数据落盘重要&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-内存数据落盘重要&#34;&gt;#&lt;/a&gt; 3、内存数据落盘（重要）&lt;/h4&gt;
&lt;p&gt;当要做增删改操作时，会对 Buffer pool 操作时， 先写 rdo log 到缓冲，然后进行落盘操作，&lt;br /&gt;
checkPoint 触发时机:&lt;br /&gt;
 假设如果重做日志可以无限增大，同时缓冲池页足够大，那么是不需要将缓冲池页的新版本刷回磁盘，因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生时刻。需要两个前提， 缓冲池中可以缓存数据库中的所有数据，重做日志可以无限增大。&lt;/p&gt;
&lt;p&gt;因此就有了 checkPoint，主要解决了 1、缩短数据库恢复时间，2、缓冲池不够用时，将脏页刷新到磁盘，3. 重做日志不可用时刷新脏页&lt;br /&gt;
 checkPonint 分类：可分为 sharp checkPonint (强制) 和 fuzzy checkPonint (模糊) ：&lt;br /&gt;
sharp checkPoint ：仅在关闭数据库的时候，将 BufferPool 中的脏页全部刷新到磁盘中，&lt;br /&gt;
fuzzy checkPoint : 数据库正常运行时，在不同的时机，将部分脏页写入磁盘，仅刷新部分脏页到磁盘。避免一次性刷新全部脏页造成性能问题。&lt;br /&gt;
有四个时机：&lt;br /&gt;
1、Master Thread CheckPoint : 主线程定时将脏页写入磁盘，每秒将脏页写入，定时落盘&lt;br /&gt;
 2、FLUSH_LRU_LIST CheckPoint 当 buffer pool 中脏页需要被淘汰时触发 checkpoint。&lt;br /&gt;
3、Async/sync Flush CheckPoint ; 异步或者同步落盘操作。跟 redolog 相关的，&lt;br /&gt;
4、Dirty Page too much CheckPoint ：buffer pool 中脏页过多时落盘，这个指标可配置&lt;/p&gt;
&lt;h4 id=&#34;4-脏页落盘过程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-脏页落盘过程&#34;&gt;#&lt;/a&gt; 4、脏页落盘过程&lt;/h4&gt;
&lt;p&gt;双写机制：&lt;br /&gt;
1、先把脏页写到 double write buffer (内存双写缓冲区)&lt;br /&gt;
 2、把 double write buffer 的数据先写到系统表空间，&lt;br /&gt;
3、把缓冲区的数据写入用户表空间中；&lt;br /&gt;
4、如果写入系统表空间发生意外导致失败，可以使用用户表空间的数据页 + redolog 恢复数据。&lt;br /&gt;
5、如果系统表空间写入成功，用户表空间写入失败，可以使用系统表空间备份的数据页来恢复用户表空间的数据页。&lt;br /&gt;
使用双写机制，保证数据落盘过程万无一失。防止再写的过程中断电，造成数据丢失。&lt;/p&gt;
&lt;h1 id=&#34;七-mysql性能优化篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#七-mysql性能优化篇&#34;&gt;#&lt;/a&gt; 七、MYSQl 性能优化篇&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;首先需要使用慢查询日志，去获取查询时间比较长的 SQL 语句&lt;/li&gt;
&lt;li&gt;查看执行计划，查看有问题的 SQL 执行计划&lt;/li&gt;
&lt;li&gt;针对查询慢的 SQL 语句进行优化&lt;/li&gt;
&lt;li&gt;使用 SHOW profile 查看有问题的 SQL 性能使用情况&lt;/li&gt;
&lt;li&gt;调整操作系参数优化&lt;/li&gt;
&lt;li&gt;升级服务器硬件&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;需要手动开启慢查询日志，需要设置阈值。&lt;/p&gt;
&lt;p&gt;#临时开启慢查询日志命令&lt;br /&gt;
 set global slow_query_log=ON&lt;br /&gt;
set global long_query_time=1&lt;br /&gt;
# 数据库重启失效，长期开启需要去配置文件启动&lt;/p&gt;
&lt;h4 id=&#34;分析慢查询日志的工具&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#分析慢查询日志的工具&#34;&gt;#&lt;/a&gt; 分析慢查询日志的工具&lt;/h4&gt;
&lt;p&gt;explain 命令 查看执行计划&lt;/p&gt;
&lt;h4 id=&#34;查看执行执行&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#查看执行执行&#34;&gt;#&lt;/a&gt; 查看执行执行&lt;/h4&gt;
&lt;p&gt;使用 explain 命令 可以对 SQL 语句的执行计划进行分析&lt;/p&gt;
&lt;p&gt;id: SELECT 查询的标识符。每个 SELECT 都会自动分配一个唯一的标识符.&lt;br /&gt;
select_type: SELECT 查询的类型.&lt;br /&gt;
table: 查询的是哪个表&lt;br /&gt;
 partitions: 匹配的分区&lt;br /&gt;
 type: join 类型 查询类型&lt;br /&gt;
 possible_keys: 此次查询中可能选用的索引&lt;br /&gt;
 key: 此次查询中确切使用到的索引.&lt;br /&gt;
ref: 哪个字段或常数与 key 一起被使用&lt;br /&gt;
 rows: 显示此查询一共扫描了多少行。这个是一个估计值.&lt;br /&gt;
filtered: 表示此查询条件所过滤的数据的百分比&lt;br /&gt;
 extra: 额外的信息&lt;/p&gt;
&lt;h4 id=&#34;sql语句的优化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#sql语句的优化&#34;&gt;#&lt;/a&gt; SQL 语句的优化&lt;/h4&gt;
&lt;h5 id=&#34;1-索引的优化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-索引的优化&#34;&gt;#&lt;/a&gt; 1、索引的优化&lt;/h5&gt;
&lt;p&gt;为搜索字段、排序字段、select 查询列建立合适的索引。&lt;br /&gt;
尽量建立组合索引，并注意顺序&lt;br /&gt;
尽量使用覆盖索引&lt;br /&gt;
索引长度尽可能短，短索引可以节省空间&lt;br /&gt;
索引的更新不能频繁，更新频繁的数据不适合建索引&lt;/p&gt;
&lt;h5 id=&#34;2-limit优化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-limit优化&#34;&gt;#&lt;/a&gt; 2、limit 优化&lt;/h5&gt;
&lt;p&gt;如果预计查询结果只有一个，建议使用 limit 1 可以停止全表扫描&lt;br /&gt;
处理分页会使用到 limit 当翻页到后面的时候偏移量会非常大， limit offset size&lt;br /&gt;
limit 优化问题，其实是 offset 的问题，他会导致 mysql 扫描大量不需要的行再抛弃掉。&lt;br /&gt;
3、其他查询优化&lt;br /&gt;
小表驱动大表，建议使用 left join 时，以小表关联大表，&lt;br /&gt;
避免全表扫描&lt;br /&gt;
 where 条件中尽量使用 Not in 语句建议使用 not exists&lt;br /&gt;
 合理利用慢查询日志，explain 执行查询计划，show profile 查看 sql 执行时的资源使用情况&lt;/p&gt;
&lt;p&gt;4、服务器端优化&lt;br /&gt;
缓冲区优化，设置足够大的 innodb_buffer_pool_size 将数据读取到内存中，&lt;br /&gt;
降低磁盘写入次数，对于生产环境来说，部分日志是可以不用的，&lt;br /&gt;
mysql 数据库配置优化 设置缓冲池内存大小&lt;br /&gt;
日志落盘配置&lt;/p&gt;
&lt;p&gt;5、操作系统优化&lt;br /&gt;
内核参数优化&lt;/p&gt;
&lt;p&gt;6、服务器硬件优化&lt;br /&gt;
提升硬件设备，例如选择尽量高频率的内存（频率不能高于主板的支持）、提升网络带宽、使用 SSD 高&lt;br /&gt;
速磁盘、提升 CPU 性能等。&lt;/p&gt;
&lt;h1 id=&#34;七-mysql集群篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#七-mysql集群篇&#34;&gt;#&lt;/a&gt; 七、MySQL 集群篇&lt;/h1&gt;
&lt;h2 id=&#34;主从复制&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#主从复制&#34;&gt;#&lt;/a&gt; 主从复制&lt;/h2&gt;
&lt;p&gt;2、binlog 和 relay 日志&lt;br /&gt;
 bin log 记录了所有数据的更改，用于本机数据恢复和主从同步&lt;br /&gt;
 relayz log ：中继日志&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;mysql 主节点将 binlog 写入本地，从节点定时请求增量 binlog，主节点将 binlog 同步到从节点&lt;/li&gt;
&lt;li&gt;从节点单独进程会将 binlog 拷贝至本地 relaylog 中&lt;/li&gt;
&lt;li&gt;从节点定时重放 relay log。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;binlog 的日志模式：&lt;br /&gt;
1.statement level 模式（日志有小概率无法同步的）&lt;br /&gt;
2.rowlevel 模式 (比较耗存储性能)&lt;br /&gt;
 3.mixed 模式（实际上就是前两种模式的结合，在 mixed 模式下）&lt;br /&gt;
在配置文件中开启开启 binlog&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#binlog刷盘策略
sync_binlog=1

0 ：存储引擎不进行binlog的刷新到磁盘，而由操作系统的文件系统控制缓存刷新。
1：每提交一次事务，存储引擎调用文件系统的sync操作进行一次缓存的刷新，这种方式最安全，但性
能较低。
n：当提交的日志组=n时，存储引擎调用文件系统的sync操作进行一次缓存的刷新。


#需要备份的数据库
binlog-do-db=hello
#不需要备份的数据库
binlog-ignore-db=mysql
#启动二进制文件
log-bin=mysql-bin
#服务器ID
server-id=132
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;调整 binlog 日志模式&lt;br /&gt;
 binlog 的三种格式： STATEMENT 、 ROW 、 MIXED 。&lt;/p&gt;
&lt;p&gt;查看 bin log 和 relay log 日志&lt;br /&gt;
因为 binlog 日志文件：mysql-bin.000005 是二进制文件，没法用 vi 等打开，这时就需要 mysql 的自带的&lt;br /&gt;
 mysqlbinlog 工具进行解码，执行： mysqlbinlog mysql-bin.000005 可以将二进制文件转为可阅读的&lt;br /&gt;
 sql 语句。&lt;/p&gt;
&lt;p&gt;3、基于 binlog 主从复制&lt;br /&gt;
关闭主从机器的防火墙&lt;/p&gt;
&lt;p&gt;主从复制存在一定延迟问题，并且只保证主机对外提供服务，只是在后台为主机进行备份。&lt;br /&gt;
配置流程&lt;br /&gt;
主服务器配置：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先做数据同步将主服务器的数据全量复制到从服务器&lt;/li&gt;
&lt;li&gt;主服务器上配置开启 binlog&lt;/li&gt;
&lt;li&gt;在主服务器上对复制数据的用户做授权操作&lt;/li&gt;
&lt;li&gt;使用 show master status 语句查看主服务器状态&lt;br /&gt;
从服务器配置：&lt;/li&gt;
&lt;li&gt;配置从服务器的 server-id 参数，在 My.cnf 文件中配置&lt;/li&gt;
&lt;li&gt;如果从服务器使用的是虚拟机，并且是通过克隆得到的虚拟机，需要删除 auto.cnf 文件，重启服务器，会重新生成此文件&lt;/li&gt;
&lt;li&gt;重启 mysql 服务&lt;/li&gt;
&lt;li&gt;change master to 命令&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;读写分离&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#读写分离&#34;&gt;#&lt;/a&gt; 读写分离&lt;/h2&gt;
&lt;p&gt;学习书籍：&lt;/p&gt;
&lt;p&gt;《从根上理解 mysql》&lt;/p&gt;
&lt;p&gt;《小林 Coding》&lt;/p&gt;
</content>
        <category term="MySQL" scheme="https://zhai-xing.github.io/mb-blog/categories/MySQL/" />
        <category term="原理" scheme="https://zhai-xing.github.io/mb-blog/tags/%E5%8E%9F%E7%90%86/" />
        <category term="学习笔记" scheme="https://zhai-xing.github.io/mb-blog/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" />
        <updated>2023-09-04T14:46:36.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8</id>
        <title>IO模式</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"/>
        <content type="html">&lt;p&gt;用户空间 user space&lt;br /&gt;
 内核空间 kernel space&lt;/p&gt;
&lt;h4 id=&#34;pio和dma&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#pio和dma&#34;&gt;#&lt;/a&gt; PIO 和 DMA&lt;/h4&gt;
&lt;p&gt;内存与硬盘数据交换方式&lt;/p&gt;
&lt;h5 id=&#34;pio&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#pio&#34;&gt;#&lt;/a&gt; PIO&lt;/h5&gt;
&lt;p&gt;磁盘和内存之间数据传输需要 CPU 控制，数据需要经过 CPU 存储转发，这种方式称为 PIO, 显然这种方式不太合理，需要大量占用 CPU 时间&lt;/p&gt;
&lt;h5 id=&#34;dma&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#dma&#34;&gt;#&lt;/a&gt; DMA&lt;/h5&gt;
&lt;p&gt;直接内存访问，取代了 PIO ，它可以不经过 CPU 而直接进行磁盘和内存（内核空间）的数据交换。&lt;/p&gt;
&lt;h4 id=&#34;缓存io和直接io&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#缓存io和直接io&#34;&gt;#&lt;/a&gt; 缓存 IO 和直接 IO&lt;/h4&gt;
&lt;p&gt;缓存 io ：数据从磁盘先通过 DMA copy 到内核空间，再从内核空间通过 CPU copy 到用户空间（Linux 默认采用）（减少与磁盘的交互次数）&lt;br /&gt;
直接 Io: 数据从磁盘通过 DMA copy 到用户空间（Mysql 就是采用这种的，）&lt;/p&gt;
&lt;h4 id=&#34;io访问方式&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#io访问方式&#34;&gt;#&lt;/a&gt; IO 访问方式&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;磁盘 IO&lt;br /&gt;
 磁盘 IO 延时是由机械硬盘转动延时 + 寻址延时 + 块传输延时决定，当然如果是固态硬盘可能会快很多。&lt;/li&gt;
&lt;li&gt;网络 IO&lt;br /&gt;
 由服务器响应延时，带宽延时 + 网络延时 + 路由跳转延时 + 本地接收延时。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;同步io和异步io&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#同步io和异步io&#34;&gt;#&lt;/a&gt; 同步 IO 和异步 IO&lt;/h4&gt;
&lt;p&gt;指的是用户空间和内核空间数据交互的方式，&lt;br /&gt;
同步：用户空间要的数据，必须等到内核空间给他才做其他事情，&lt;br /&gt;
异步：用户空间要的数据，不需要等到内核空间给他，才做其他事情，内核空间会异步通知用户进程，并把数据直接给到用户空间，&lt;/p&gt;
&lt;h4 id=&#34;阻塞io和非阻塞io&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#阻塞io和非阻塞io&#34;&gt;#&lt;/a&gt; 阻塞 Io 和非阻塞 IO&lt;/h4&gt;
&lt;p&gt;阻塞方式下读取或者写入函数将一直等待，&lt;br /&gt;
而非阻塞方式下，读取或者写入函数会立即返回一个状态值，&lt;/p&gt;
&lt;h4 id=&#34;io设计模式-reactor和proactor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#io设计模式-reactor和proactor&#34;&gt;#&lt;/a&gt; IO 设计模式 Reactor 和 Proactor&lt;/h4&gt;
&lt;h5 id=&#34;reactor-模式&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#reactor-模式&#34;&gt;#&lt;/a&gt; Reactor 模式&lt;/h5&gt;
&lt;p&gt;是一种处理并发服务请求，并将请求提交到一个或者多个服务处理程序的事件设计模式，当客户端请求抵达后，服务处理处理程序来接收所有的请求，然后派发这些请求至相关的工作线程进行处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始事件分发器&lt;br /&gt;
用于管理 Event Handler 定义注册、移除 EventHandler&lt;/li&gt;
&lt;li&gt;同步事件分类器 ：&lt;br /&gt;
无限循环等待新事件的到来，一旦发现有新的事件到来 就通知事件分发器去调取&lt;/li&gt;
&lt;li&gt;系统处理程序：操作系统中的句柄，实在&lt;/li&gt;
&lt;li&gt;事件处理器：定义事件处理方法&lt;br /&gt;
如果使用多线程处理：会为每个单独到来的请求，专门启动一条线程，这样的话，造成系统的开销很大，并且再单核的机上，多线程并不能提高系统的性能，除非在一些有阻塞的情况发生，否则线程切换的开销会使处理的速度变慢。&lt;br /&gt;
Reactor 模式 ：是启动一条单线程，用于轮询 IO 操作是否就绪，当有就绪的才进行相应的读写操作，这样的话就减少了服务器产生大量的线程，也不会出现线程之间切换产生的性能损耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;五种io模型&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#五种io模型&#34;&gt;#&lt;/a&gt; 五种 IO 模型&lt;/h4&gt;
&lt;p&gt;同步阻塞 IO&lt;br /&gt;
 同步非阻塞 IO&lt;br /&gt;
IO 多路复用&lt;br /&gt;
异步 IO: 经典的 Proactor 设计模式，也称为异步阻塞 IO&lt;/p&gt;
</content>
        <category term="计算机基础" scheme="https://zhai-xing.github.io/mb-blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" />
        <category term="IO模式" scheme="https://zhai-xing.github.io/mb-blog/tags/IO%E6%A8%A1%E5%BC%8F/" />
        <category term="计算机基础" scheme="https://zhai-xing.github.io/mb-blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" />
        <updated>2023-09-03T15:06:54.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/Python%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4</id>
        <title>Python自动化运维</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/Python%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4"/>
        <content type="html">&lt;h3 id=&#34;系统模块&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#系统模块&#34;&gt;#&lt;/a&gt; 系统模块&lt;/h3&gt;
&lt;p&gt;系统模块主要是使用 psutil 库，后面会主要写这个介绍一下&lt;br /&gt;
 psutil 是一个跨平台库，能够轻松实现获取系统运行的进程和系统利用率（包括 cpu 磁盘 网络等信息）&lt;/p&gt;
&lt;h4 id=&#34;常用psutil监控指标&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#常用psutil监控指标&#34;&gt;#&lt;/a&gt; 常用 psutil 监控指标&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;import psutil
print(psutil.cpu_count(logical=False)) # 返回cpu核心数 参数默认true 如果是false仅返回物理核心数
print(psutil.virtual_memory()) # 返回内存信息 元组(全部，已用，百分比，使用过，未使用过，)
li=psutil.virtual_memory().total # 拿到内存 拿到的是比特
print(int(li)/1024/1024/1024) # 转换成gb

print(psutil.disk_partitions()) # 查看磁盘信息
print(psutil.disk_usage(&amp;quot;D:\\&amp;quot;).percent)  #查看磁盘利用情况 当然后面也可以带一些其他参数，需要什么就带什么，具体可以看文档
print(psutil.disk_usage(&amp;quot;F:\\&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;运行效果&lt;/strong&gt;&lt;br /&gt;
&lt;img data-src=&#34;:/1a014c7a398f47f4aff09db1d677e3f3&#34; alt=&#34;66980eb9f2dc159fddd615edbac03370.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;使用psutil查看系统进程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#使用psutil查看系统进程&#34;&gt;#&lt;/a&gt; 使用 psutil 查看系统进程&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;import psutil
print(psutil.pids()) # 返回运行程序清单 list 里面是pid
print(psutil.Process(896))  #传入pid 可以拿到这个id对应的程序情况，并且返回一些信息 当然返回也是list
print(psutil.Process(896).exe()) # 返回程序所在位置
print(psutil.Process(896).connections()) # 返回程序连接信息 本地ip 远程ip 端口 状态等，可以使用它进行监控程序运行信息
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;运行效果&lt;/strong&gt;&lt;br /&gt;
&lt;img data-src=&#34;:/6a59222469e24f92980a7a605ef90ead&#34; alt=&#34;71b4fa0d10ae35aabcc56b0a479bf8c5.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;演示用popen获取用户进程信息&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#演示用popen获取用户进程信息&#34;&gt;#&lt;/a&gt; 演示用 popen 获取用户进程信息&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-from&#34;&gt;import psutil
p=psutil.Popen([&amp;quot;D:\python\python\python.exe&amp;quot;,&amp;quot;-c&amp;quot;,&amp;quot;print(&#39;hello&#39;)&amp;quot;],stdout=PIPE)  # 运行一个程序
print(p.name())  # 返回程序由什么程序运行
print(p.username()) # 返回运行在那个用户下
print(p.cpu_times) #返回 占用cup的信息
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;运行效果&lt;/strong&gt;&lt;br /&gt;
&lt;img data-src=&#34;:/4e40d8a537124afab5f0791d6c0806e5&#34; alt=&#34;4ec7aef3ea08e4cab03376c5ca619be3.png&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;ip地址处理模块&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ip地址处理模块&#34;&gt;#&lt;/a&gt; IP 地址处理模块&lt;/h3&gt;
&lt;p&gt;主要是使用 IPy 这个包 ，使用这个库，可以处理绝大部分 IPV6 和 IPV4 的网络和地址&lt;/p&gt;
&lt;h3 id=&#34;dns模块&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#dns模块&#34;&gt;#&lt;/a&gt; Dns 模块&lt;/h3&gt;
&lt;p&gt;主要是使用 dns 工具包，可以查询动态更新 ZONEx 信息，所谓 dns 服务就是将域名转换为 ip 地址，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A 记录 ：将主机名转换成 IP 地址&lt;/li&gt;
&lt;li&gt;MX 记录 ：邮件交换记录，定义邮件服务器的域名，&lt;/li&gt;
&lt;li&gt;CNAME 记录 ，指别名记录，实现域名间的映射&lt;/li&gt;
&lt;li&gt;NS 记录 标记区域的域名服务器及授权子域；&lt;/li&gt;
&lt;li&gt;PTR 记录 反向解析，与 A 记录相反，将 IP 转换成主机名&lt;/li&gt;
&lt;li&gt;SOAj 记录，SOA 标记，一个起始授权区的定义&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常见解析类型示例说明&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#常见解析类型示例说明&#34;&gt;#&lt;/a&gt; 常见解析类型示例说明&lt;/h3&gt;
&lt;p&gt;常见的 DNS 解析类型包括 A、MX、NS、CNAME 等利用 dnspython 的 dnsresoler.&lt;br /&gt;
query 方法可以简单实现这些 DNS 类型的查询，为后面要实现的功能提供数据来源。例如一个使用 DNS 轮询业务的域名进行可用性监控，需要得到当前的解析结果。&lt;/p&gt;
&lt;h3 id=&#34;本地dns搭建&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#本地dns搭建&#34;&gt;#&lt;/a&gt; 本地 DNS 搭建&lt;/h3&gt;
&lt;h3 id=&#34;演示dns功能&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#演示dns功能&#34;&gt;#&lt;/a&gt; 演示 DNS 功能&lt;/h3&gt;
&lt;h3 id=&#34;网站监控监测&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#网站监控监测&#34;&gt;#&lt;/a&gt; 网站监控监测&lt;/h3&gt;
&lt;h3 id=&#34;邮件发送模块&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#邮件发送模块&#34;&gt;#&lt;/a&gt; 邮件发送模块&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;简单邮件发送&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;import smtplib

HOST=&amp;quot;smtp.qq.com&amp;quot;
SUBJECT=&amp;quot;CES&amp;quot;
FROM=&amp;quot;1174115923@qq.com&amp;quot;
TO=&amp;quot;1298391806@qq.com&amp;quot;
text=&amp;quot;摘星&amp;quot;

BODY=&amp;quot;\n&amp;quot;.join(
    (&amp;quot;来自：%s&amp;quot;%FROM,&amp;quot;目的地：%s&amp;quot;%TO,&amp;quot;项目：%s&amp;quot;%SUBJECT,&amp;quot;text: %s&amp;quot;%text)
).encode(encoding=&amp;quot;utf-8&amp;quot;) # 解决编码问题

server=smtplib.SMTP(HOST)
server.login(&amp;quot;1174115923@qq.com&amp;quot;,&amp;quot;iyjohyjovxrsjbfa&amp;quot;)
server.sendmail(FROM,[TO],BODY)
server.quit()```
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="Python" scheme="https://zhai-xing.github.io/mb-blog/categories/Python/" />
        <category term="自动化运维" scheme="https://zhai-xing.github.io/mb-blog/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/" />
        <updated>2023-03-07T17:03:44.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/JUC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0</id>
        <title>JUC学习笔记</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/JUC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"/>
        <content type="html">&lt;h3 id=&#34;11-进程与线程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-进程与线程&#34;&gt;#&lt;/a&gt; 1.1 进程与线程&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;进程基本上是相互独立的，而线程存在于进程内，一个进程内可存在多个线程，同一个进程内多个线程可以访问一个共享的内存空间，线程间的通信很简单，因为他们共享进程内的内存。线程更轻量，线程的上下文切换成本一般要比进程的上下文切换低&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Java 中，线程作为最小的调度单位，进程作为资源分配的最小单位，在 windows 中，进程是线程的容器。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进程间的通信较为复杂，同一台计算机的进程通信称为 IPC，而不同计算机之间的进程通信，则需要通过网络来实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当一个程序被运行，从磁盘加载这个程序的代码到内存，这时就开启了一个进程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进程可看作程序的一个实例，大部分程序可同时运行多个实例进程，当然也有部分程序只能同时启动一个实例进程。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;22-并行与并发&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-并行与并发&#34;&gt;#&lt;/a&gt; 2.2 并行与并发&lt;/h3&gt;
&lt;p&gt;在单核 cpu 下，线程实际还是按串行指向的，操作系统中有一个组件叫任务调度器，将 CPU 的时间片分配给不同的程序使用，只是由于 CPU 在线程间的切换非常快，人类感觉是同时运行的。将这种多个线程轮流使用 CPU 的做法称为并发。&lt;/p&gt;
&lt;p&gt;而在多核 CPU 下，每个核都可以调度运行线程，这种情况下，线程是可以并行的。&lt;/p&gt;
&lt;p&gt;并发：是同一时间&lt;strong&gt;应对&lt;/strong&gt;多件事情的能力&lt;br /&gt;
并行：是同一时间&lt;strong&gt;动手做&lt;/strong&gt;多件事情的能力&lt;/p&gt;
&lt;h3 id=&#34;31java创建和运行线程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31java创建和运行线程&#34;&gt;#&lt;/a&gt; 3.1Java 创建和运行线程&lt;/h3&gt;
&lt;p&gt;方法一：直接使用 Thread&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;**package com.zx.itcast.test;

import lombok.extern.slf4j.Slf4j;

@Slf4j(topic = &amp;quot;test2&amp;quot;)
public class Test2 &amp;#123;
    public static void main(String[] args) &amp;#123;
       Thread thread=new Thread()&amp;#123;
           @Override
           public void run()&amp;#123;
               System.out.println(&amp;quot;线程的任务&amp;quot;);
           &amp;#125;
       &amp;#125;;
       //运行线程
       thread.start();

    &amp;#125;
&amp;#125;
**
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;方法二：使用 Runnable 配合 Thread&lt;br /&gt;
 使用 Runnable 可把线程和任务分开，&lt;/p&gt;
&lt;p&gt;Thread 代表线程&lt;br /&gt;
 Runnable 代表要运行的任务&lt;br /&gt;
使用了 Runnable 可更容易与线程池等高级 API 配合&lt;br /&gt;
用 Runnable 让任务类脱离了 Thread 继承体系，&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.zx.itcast.test;

import lombok.extern.slf4j.Slf4j;

@Slf4j(topic = &amp;quot;test2&amp;quot;)
public class Test2 &amp;#123;
    public static void main(String[] args) &amp;#123;
        //创建要执行的任务
       Runnable runnable=new Runnable() &amp;#123;
           @Override
           public void run() &amp;#123;
               System.out.println(&amp;quot;执行的任务&amp;quot;);
           &amp;#125;
       &amp;#125;;
       
       //创建Thread 将runnable作为参数传进去
        Thread thread=new Thread(runnable);
        
       //启动线程
       thread.start();

    &amp;#125;
&amp;#125;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;方法三：FutureTask 配合 Thread&lt;br /&gt;
FutureTask 能够接收 Callable 类型的参数，用来处理有返回结果的情况。&lt;br /&gt;
使用 FutureTask 可以处理线程运行完有结果的情况&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.zx.itcast.test;

import lombok.extern.slf4j.Slf4j;


import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;

@Slf4j(topic = &amp;quot;test2&amp;quot;)
public class Test2 &amp;#123;
    public static void main(String[] args) throws ExecutionException, InterruptedException &amp;#123;
        
        FutureTask&amp;lt;String&amp;gt; futureTask=new FutureTask&amp;lt;String&amp;gt;(()-&amp;gt;&amp;#123;
            System.out.println(&amp;quot;执行的&amp;quot;);
            return &amp;quot;任务&amp;quot;;
        &amp;#125;);

        new Thread(futureTask).start();
        System.out.println(futureTask.get());

    &amp;#125;
&amp;#125;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;32栈与栈帧&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#32栈与栈帧&#34;&gt;#&lt;/a&gt; 3.2 栈与栈帧&lt;/h3&gt;
&lt;p&gt;JVM 由栈、堆、方法区组成，其中栈内存是给线程使用的，每个线程启动后，虚拟机就会为其分配一个栈内存&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个栈由多个栈帧组成，对应着每次方法调用时占用的内存&lt;/li&gt;
&lt;li&gt;每个线程只能有一个活动栈帧对应着正在执行的那个方法&lt;br /&gt;
&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230308000938666.png&#34; alt=&#34;image-20230308000938666&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;33上下文切换&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#33上下文切换&#34;&gt;#&lt;/a&gt; 3.3 上下文切换&lt;/h3&gt;
&lt;p&gt;因为以下原因导致 cpu 不再执行当前的线程，转而执行另一个线程的代码&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程的 CPU 时间用完&lt;/li&gt;
&lt;li&gt;垃圾回收有更高优先级的线程需要运行&lt;/li&gt;
&lt;li&gt;线程自己调用了 sleep、yield、wait、park、lock 等方法&lt;br /&gt;
当然了频繁的上下文切换，会影响性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;34常用的方法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#34常用的方法&#34;&gt;#&lt;/a&gt; 3.4 常用的方法&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230308001025831.png&#34; alt=&#34;image-20230308001025831&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230308001047901.png&#34; alt=&#34;image-20230308001047901&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230308001057342.png&#34; alt=&#34;image-20230308001057342&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;341-start与run&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#341-start与run&#34;&gt;#&lt;/a&gt; 3.4.1 start 与 run&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;直接调用 run 是在主线程中执行了 run，没有启动新的线程，还是同步执行的。&lt;/li&gt;
&lt;li&gt;使用 start 是启动新的线程，通过新的线程间接执行 run 中的代码&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;342-sleep与yield&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#342-sleep与yield&#34;&gt;#&lt;/a&gt; 3.4.2 sleep 与 yield&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Sleep&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调用 sleep 会让当前线程从 Running 进入 Timed Waiting 状态（阻塞，有时限的等待）&lt;/li&gt;
&lt;li&gt;其它线程可以使用 interrupt 方法打断正在睡眠的线程，这时 sleep 方法会抛出 InterruptedException&lt;/li&gt;
&lt;li&gt;睡眠结束后的线程未必会立刻得到执行&lt;/li&gt;
&lt;li&gt;建议用 TimeUnit 的 sleep 代替 Thread 的 sleep 来获得更好的可读性 (sleep 底层也是使用的 TimeUnir 的。可读性要好点)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;yield&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调用 yield 会让当前线程从 Running 进入 Runnable 就绪状态，然后调度执行其它线程&lt;/li&gt;
&lt;li&gt;具体的实现依赖于操作系统的任务调度器&lt;/li&gt;
&lt;li&gt;当你让出时间片时，可能会没有线程来使用，这样就会出现让不出去的情况。还会执行自己的&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;mark&gt;sleep 与 yield 的区别：sleep 是会让线程进入阻塞态，阻塞态的线程是不会获得时间片的。而 yield 会让线程进入就绪态，还会有可能被分配时间片执行。&lt;/mark&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线程优先级&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程优先级会提示（hint）调度器优先调度该线程，但它仅仅是一个提示，调度器可以忽略它&lt;/li&gt;
&lt;li&gt;如果 cpu 比较忙，那么优先级高的线程会获得更多的时间片，但 cpu 闲时，优先级几乎没作用&lt;/li&gt;
&lt;li&gt;最小优先级 1 最大优先级 10  默认优先级为 5；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;344-join&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#344-join&#34;&gt;#&lt;/a&gt; 3.4.4 join&lt;/h4&gt;
&lt;p&gt;等待线程结束，等待那个线程结束，就用那个线程实例去调用 join 方法。&lt;br /&gt;
在等待线程结束时，可在 join 里加入参数，可设置最大等待时间。&lt;/p&gt;
&lt;p&gt;同步：需要等待返回结果后才能继续运行的就是同步，&lt;/p&gt;
&lt;p&gt;异步：不需要等待结果返回，就能继续运行就是异步，&lt;/p&gt;
&lt;h4 id=&#34;345-interrupt方法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#345-interrupt方法&#34;&gt;#&lt;/a&gt; 3.4.5 interrupt 方法&lt;/h4&gt;
&lt;p&gt;打断正在睡眠的方法，例如 sleep（睡眠）、wait、join（等待结果）的线程，被打断的线程会抛出异常&lt;br /&gt;
如果线程是正在执行的情况下，这个线程并不会收到影响，只是会被标记为被打断过。&lt;/p&gt;
&lt;h4 id=&#34;346-isinterrupted-方法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#346-isinterrupted-方法&#34;&gt;#&lt;/a&gt; 3.4.6 isInterrupted () 方法&lt;/h4&gt;
&lt;p&gt;获取打断标记。&lt;br /&gt;
如果线程被打断过，调用该方法返回 true 否则返回 false&lt;br /&gt;
 注：如果线程状态是 sleep wait join 状态的线程被打断后，会被标记为 false 因为会抛出异常。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) throws ExecutionException, InterruptedException &amp;#123;
        Runnable re=new Runnable() &amp;#123;
            @Override
            public void run() &amp;#123;
                while (true)&amp;#123;
                    boolean is=Thread.currentThread().isInterrupted();
                    if(is)&amp;#123;
                        log.debug(&amp;quot;被打断了&amp;quot;);
                        break;
                    &amp;#125;
                &amp;#125;
            &amp;#125;
        &amp;#125;;
        Thread thread=new Thread(re,&amp;quot;t1&amp;quot;);
        thread.start();
       Thread.sleep(1000);
       log.debug(&amp;quot;interrupt&amp;quot;);
       thread.interrupt();
    &amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;设计模式-两阶段终止&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#设计模式-两阶段终止&#34;&gt;#&lt;/a&gt; 设计模式 - 两阶段终止&lt;/h4&gt;
&lt;p&gt;在一个线程 t1 中，如果优雅的终止 t2 线程，这里的优雅是指给 t2 一个处理善后工作的机会。&lt;br /&gt;
错误思路 1&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;使用线程对象提供的 stop () 方法停止线程，&lt;br /&gt;
stop 方法会真正的杀死线程，如果这时线程锁住了共享资源，那么当他被杀死后就再也没机会释放锁，其他线程将永远无法获取锁.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 system.exit 方法停止线程：目的是停止一个线程，但这种做法会让整个程序都停止&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230308001114190.png&#34; alt=&#34;image-20230308001114190&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Slf4j(topic = &amp;quot;c.Test1&amp;quot;)
public class Test &amp;#123;
    public static void main(String[] args) throws ExecutionException, InterruptedException &amp;#123;
        TwoPhaseTermination twoPhaseTermination=new TwoPhaseTermination();
        twoPhaseTermination.start();
        Thread.sleep(5000);
        twoPhaseTermination.stop();

    &amp;#125;
    static class TwoPhaseTermination&amp;#123;
        private Thread monitor;

        public void start()&amp;#123;
            monitor=new Thread(()-&amp;gt;&amp;#123;
                while (true)&amp;#123;
                    Thread  cur=Thread.currentThread();
                    if(cur.isInterrupted())&amp;#123;
                        log.debug(&amp;quot;处理后事&amp;quot;);
                        break;
                    &amp;#125;

                    try &amp;#123;
                        Thread.sleep(1300);
                        log.debug(&amp;quot;执行监控记录&amp;quot;);
                    &amp;#125; catch (InterruptedException e) &amp;#123;
                        e.printStackTrace();
                        //重新设置打断标记
                        cur.interrupt();
                    &amp;#125;
                &amp;#125;
            &amp;#125;);
            monitor.start();
        &amp;#125;
        public void stop()&amp;#123;
            monitor.interrupt();
        &amp;#125;
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;守护线程与主线程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#守护线程与主线程&#34;&gt;#&lt;/a&gt; 守护线程与主线程&lt;/h4&gt;
&lt;p&gt;默认情况下，Java 进程要等待所有线程结束才会结束，但是有一种特殊的线程叫守护线程，只需要其他非守护线程运行结束了，即使守护线程的代码没有执行完，也会强制结束。&lt;br /&gt;
可以使用 .setDaemon (true); 方法设置为守护线程&lt;/p&gt;
&lt;p&gt;注：垃圾收回器线程就是一种守护线程&lt;br /&gt;
 tomcat 中的 accept 和 poller 线程都是守护线程，所以 tomcat 接收到 shutdown 命令后，不会等待他们处理完当前请求。&lt;/p&gt;
&lt;h4 id=&#34;1-线程五种状态&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-线程五种状态&#34;&gt;#&lt;/a&gt; 1、 线程五种状态&lt;/h4&gt;
&lt;p&gt;操作系统层面&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;初始状态：仅仅在语言层面创建了线程对象&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;就绪状态：该线程已经被创建，可以由 cpu 调度运行&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;运行状态：指获取了 cpu 时间片运行中的状态&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;阻塞状态：调用了阻塞 api, 这时线程不会用到 cpu 会导致线程上下文切换，进入阻塞状态，等待操作执行完，会由操作系统唤醒阻塞的线程，转换为可执行也就是就绪状态，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;终止状态：线程已经执行完毕，生命周期已经结束，不会再转换状态。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;2-线程的六种状态&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-线程的六种状态&#34;&gt;#&lt;/a&gt; 2、线程的六种状态&lt;/h4&gt;
&lt;p&gt;Java 层面&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;new 线程刚刚被创建，但是还没有调用 start 方法&lt;/li&gt;
&lt;li&gt;RUNNABLE 当调用了 start 方法后，注意 javaapi 层面的 runnable 状态涵盖了操作系统层面的可运行状态，运行状态，阻塞状态， 由于 bios 导致的线程阻塞 在 Java 里无法区分，仍然认为是可运行的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;4共享模型&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4共享模型&#34;&gt;#&lt;/a&gt; 4. 共享模型&lt;/h3&gt;
&lt;p&gt;多线程访问带来的问题&lt;br /&gt;
多线程下，读写共享资源，由于分时系统，线程间上下文切换时（指令的交错）会导致线程不安全。&lt;br /&gt;
例如 I++&lt;br /&gt;
Java 中对于静态变量的自增、自减，并不是原子性操作。需要分成三条指令去完成，&lt;br /&gt;
取值，自增，写值，&lt;/p&gt;
&lt;h4 id=&#34;41-临界区与竟态条件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#41-临界区与竟态条件&#34;&gt;#&lt;/a&gt; 4.1 临界区与竟态条件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;一个程序运行多个线程本身是没有问题的，&lt;/li&gt;
&lt;li&gt;问题出现在多个线程访问共享资源&lt;/li&gt;
&lt;li&gt;多个线程对共享资源进行读操作也是没有问题的&lt;/li&gt;
&lt;li&gt;问题在于多个线程对共享资源进行读写操作时，发生指令交错，就会出现问题&lt;/li&gt;
&lt;li&gt;一段代码如果存在对共享资源的多线程读写操作，称这段代码为临界区&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;竞态条件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#竞态条件&#34;&gt;#&lt;/a&gt; 竞态条件&lt;/h5&gt;
&lt;p&gt;多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测，称之为发生了竟态条件。&lt;/p&gt;
&lt;h4 id=&#34;解决方案&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#解决方案&#34;&gt;#&lt;/a&gt; 解决方案&lt;/h4&gt;
&lt;p&gt;为了避免临界区的竟态条件发生，有多种手段可以达到目的，&lt;br /&gt;
阻塞式解决方案： synchronized ，Lock&lt;br /&gt;
 非阻塞式解决方案：原子变量&lt;/p&gt;
&lt;h5 id=&#34;synchronized&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#synchronized&#34;&gt;#&lt;/a&gt; synchronized&lt;/h5&gt;
&lt;p&gt;俗称对象锁，采用互斥的方式让同一时刻最多只有一个线程能持有对象锁，其他线程再想获取这个对象锁时就会阻塞，这样就能保证拥有锁的线程可以安全的执行临界区内的代码，不用担心线程上下文切换。&lt;/p&gt;
&lt;p&gt;注：虽然 Java 中互斥和同步都可以采用 synchronized 关键字来完成，但是他们还是有区别的，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;互斥是保证临界区的竟态条件发生，同一时刻只能有一个线程执行临界区代码。&lt;/li&gt;
&lt;li&gt;同步是由于线程执行的先后、顺序不同，需要一个线程等待其他线程运行到某个点。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;package com.zx.itcast.test;
import lombok.SneakyThrows;
import lombok.extern.slf4j.Slf4j;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;
import java.util.concurrent.TimeUnit;
@Slf4j(topic = &amp;quot;c.Test1&amp;quot;)
public class Test &amp;#123;
    static int res=0;
    static Object lock=new Object();
    public static void main(String[] args) throws InterruptedException &amp;#123;

        Thread thread=new Thread(()-&amp;gt;&amp;#123;
            for(int i=0;i&amp;lt;5000;i++)&amp;#123;
                synchronized (lock)&amp;#123;
                    res++;
                &amp;#125;
            &amp;#125;
        &amp;#125;,&amp;quot;t1&amp;quot;);
        Thread thread2=new Thread(()-&amp;gt;&amp;#123;
            for(int i=0;i&amp;lt;5000;i++)&amp;#123;
                synchronized (lock)&amp;#123;
                    res--;
                &amp;#125;
            &amp;#125;
        &amp;#125;,&amp;quot;t2&amp;quot;);
        thread.start();
        thread2.start();
        thread.join();
        thread2.join();
        System.out.println(res);
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;synchronizd 实际上是使用了对象锁保证了临界区代码的原子性，临界区内的代码对外是不可分割的，不会被线程切换所打断&lt;/p&gt;
&lt;h5 id=&#34;synchronized写在方法上&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#synchronized写在方法上&#34;&gt;#&lt;/a&gt; synchronized 写在方法上&lt;/h5&gt;
&lt;p&gt;synchronized 加在成员方法上，是锁住了 this 对象&lt;br /&gt;
 synchronized 在在了静态方法上，是锁住了这个类对象&lt;/p&gt;
&lt;h4 id=&#34;线程安全分析&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#线程安全分析&#34;&gt;#&lt;/a&gt; 线程安全分析&lt;/h4&gt;
&lt;h5 id=&#34;成员变量和静态变量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#成员变量和静态变量&#34;&gt;#&lt;/a&gt; 成员变量和静态变量&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;如果他们没有共享，则线程安全，&lt;/li&gt;
&lt;li&gt;如果他们被共享了，根据他们的状态是否能够改变又分为两种情况&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;如果只有读情况，则线程安全，&lt;/li&gt;
&lt;li&gt;如果有写操作，则这段代码是临界区，需要考虑线程安全&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;局部变量&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#局部变量&#34;&gt;#&lt;/a&gt; 局部变量&lt;/h5&gt;
&lt;p&gt;局部变量是线程安全的，但局部变量引用的对象未必&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果该对象没有逃离方法的作用访问，则他是线程安全的&lt;/li&gt;
&lt;li&gt;如果该对象逃离方法的作用范围，需要考虑线程安全&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;常用的线程安全类&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#常用的线程安全类&#34;&gt;#&lt;/a&gt; 常用的线程安全类&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;String&lt;/li&gt;
&lt;li&gt;Integer&lt;/li&gt;
&lt;li&gt;StringBuffer&lt;/li&gt;
&lt;li&gt;Random&lt;/li&gt;
&lt;li&gt;Vector&lt;/li&gt;
&lt;li&gt;Hashtable   注: HashMap 不是线程安全的；&lt;/li&gt;
&lt;li&gt;java.util.concurrent 下的类&lt;br /&gt;
这里说他们是线程安全的是指 多个线程调用他们同一个实例的某个方法时，是线程安全的，也可以理解为。他们的每个方法是原子的，但是请注意，他们多个方法的组合不是原子的&lt;/li&gt;
&lt;li&gt;一般局部变量是线程安全的（如果不暴露出修改方法），而成员变量，可能是不安全的&lt;/li&gt;
&lt;li&gt;私有的成员变量，是线程安全的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;synchronized优化原理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#synchronized优化原理&#34;&gt;#&lt;/a&gt; synchronized 优化原理&lt;/h3&gt;
&lt;h5 id=&#34;monitor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#monitor&#34;&gt;#&lt;/a&gt; Monitor&lt;/h5&gt;
&lt;p&gt;对象由两部分组成，一部分是对象头， 另一部分就是对象中的一些成员变量。&lt;br /&gt;
每个 Java 对象都可以关联一个 Monitor 对象，如果使用 synchronized 给对象上锁之后，该对象的 MarkWord 中就被设置指向 Monitor 对象的指针。&lt;/p&gt;
&lt;h5 id=&#34;轻量级锁&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#轻量级锁&#34;&gt;#&lt;/a&gt; 轻量级锁&lt;/h5&gt;
&lt;p&gt;应用场景： 如果一个对象虽然有多个线程访问，但多线程访问的时间是错开的（也就是没有竞争）那么可以使用轻量级锁来优化。&lt;/p&gt;
&lt;p&gt;轻量级锁对使用者来说是透明的，&lt;/p&gt;
&lt;h5 id=&#34;偏向锁&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#偏向锁&#34;&gt;#&lt;/a&gt; 偏向锁&lt;/h5&gt;
&lt;h3 id=&#34;wait-ify-原理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#wait-ify-原理&#34;&gt;#&lt;/a&gt; wait ify 原理&lt;/h3&gt;
&lt;h4 id=&#34;原理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#原理&#34;&gt;#&lt;/a&gt; 原理&lt;/h4&gt;
&lt;p&gt;&lt;img data-src=&#34;https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230308001138286.png&#34; alt=&#34;image-20230308001138286&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Owner 会在线程条件不满足时，调用 wait 方法 即可进入 WaitSet 变为 WAITING 状态&lt;/li&gt;
&lt;li&gt;BLOCKED 和 WAITING 的线程都处于阻塞状态，不占用时间片&lt;/li&gt;
&lt;li&gt;BLOCKED 的线程会在 Owner 线程释放锁时被唤醒&lt;/li&gt;
&lt;li&gt;WAITING 线程调用 notify 或 notifyAll 时唤醒，但是唤醒后不意味着立刻即可获得锁，仍需要进入 EntryList 竞争&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;对象锁api&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#对象锁api&#34;&gt;#&lt;/a&gt; 对象锁 API&lt;/h4&gt;
&lt;p&gt;obj.wait () 让进入 object 监视器的线程到 waitSet 等待&lt;br /&gt;
 obj.notify () 让在 object 上正在 waitSet 等待的线程中挑一个唤醒&lt;br /&gt;
 obj.notifyAll () 让 object 上正在 waitSet 等待的线程全部唤醒&lt;br /&gt;
 obj.wait (long timeout) 让进入 object 监视器的线程到 waitSet 等待一段时间，时间到了自动唤醒&lt;/p&gt;
&lt;p&gt;他们都是线程之间进行协作的手段，&lt;strong&gt;都属于 Object 对象的方法，必须获得此对象的锁&lt;/strong&gt;，才能调用这几个方法&lt;/p&gt;
&lt;h4 id=&#34;sleep和waitlong-n的区域&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#sleep和waitlong-n的区域&#34;&gt;#&lt;/a&gt; sleep 和 wait (long n) 的区域&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;sleep 是 Thread 方法，wait 是 Object 的方法&lt;/li&gt;
&lt;li&gt;sleep 不需要强制和 synchronized 配合使用，但 wait 需要和 synchronized 一起用&lt;/li&gt;
&lt;li&gt;sleep 在睡眠同时，不会释放对象锁，但 wait 在等待的时候会释放对象锁&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;同步模式之保护性暂停&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#同步模式之保护性暂停&#34;&gt;#&lt;/a&gt; 同步模式之保护性暂停&lt;/h4&gt;
&lt;p&gt;主要是用在一个线程等待另一个线程的执行结果时&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有一个结果需要从一个线程传送到另一个线程，让他们关联同一个 GuardedObject&lt;/li&gt;
&lt;li&gt;如果有结果源源不断的从一个线程传递到另一个线程，那么可以使用消息队列&lt;/li&gt;
&lt;li&gt;JDK 中 join 的实现 Futrue 的实现，采用的就是这个模式&lt;/li&gt;
&lt;li&gt;因为要等待另一方的结果，所以归类到同步模式&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;package com.zx.itcast.test;
import lombok.extern.slf4j.Slf4j;

@Slf4j(topic = &amp;quot;test2&amp;quot;)
public class Test2 &amp;#123;

    private Object response;
    public Object get()&amp;#123;
        synchronized (this)&amp;#123;
            while(response==null)&amp;#123;
                try &amp;#123;
                    //让他等待
                    this.wait();
                &amp;#125; catch (InterruptedException e) &amp;#123;
                    e.printStackTrace();
                &amp;#125;
            &amp;#125;
            return response;
        &amp;#125;
    &amp;#125;
    //产生结果
    public void complete(Object response)&amp;#123;
        synchronized (this)&amp;#123;
            this.response=response;
            this.notify();
        &amp;#125;
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也可以增强超时的处理&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.zx.itcast.n3;

/**
 * 带超时的暂停
 */
public class GuardedObject &amp;#123;
    //结果
    private  Object resonse;
    //锁对象
    private final  Object lock=new Object();
    //获取结果的方法
    public Object get(long millis) &amp;#123;
        synchronized (lock)&amp;#123;
            //开始等待时间
            long begin=System.currentTimeMillis();
            //已经经历的时间
            long timePassed=0;
            while(resonse==null)&amp;#123;
                long waitTime=millis-timePassed;
                if(waitTime&amp;lt;0)&amp;#123;
                    break;
                &amp;#125;
                try &amp;#123;
                    lock.wait(waitTime);
                &amp;#125;catch (InterruptedException e)&amp;#123;
                    e.printStackTrace();
                &amp;#125;

                timePassed=System.currentTimeMillis()-begin;
            &amp;#125;
            return resonse;
        &amp;#125;
    &amp;#125;
    public void compltet(Object resonse)&amp;#123;
        synchronized (lock)&amp;#123;
            this.resonse=resonse;
            lock.notifyAll();
        &amp;#125;
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;异步模式-生产者消费者模式&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#异步模式-生产者消费者模式&#34;&gt;#&lt;/a&gt; 异步模式 --- 生产者消费者模式&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;与前面的保护性暂停中国的 Guardobject 不同，不需要产生结果和消费结果的线程一一对应，&lt;/li&gt;
&lt;li&gt;消费队列可以用来平衡生产和消费的线程资源&lt;/li&gt;
&lt;li&gt;生产者仅负责产生结果数据，不关心数据如何处理，而消费者专注于数据处理，&lt;/li&gt;
&lt;li&gt;消息队列有容量机制，满时不会再加入数据，空时不会再消耗数据&lt;/li&gt;
&lt;li&gt;jdk 中各种阻塞队列 就是使用的这种模式&lt;/li&gt;
&lt;/ul&gt;
</content>
        <category term="java" scheme="https://zhai-xing.github.io/mb-blog/categories/java/" />
        <category term="异步设计模式" scheme="https://zhai-xing.github.io/mb-blog/categories/%E5%BC%82%E6%AD%A5%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" />
        <category term="JUC" scheme="https://zhai-xing.github.io/mb-blog/tags/JUC/" />
        <category term="多线程" scheme="https://zhai-xing.github.io/mb-blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/" />
        <updated>2023-03-07T16:12:31.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/Java%E5%B8%B8%E7%94%A8%E5%AE%B9%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0</id>
        <title>Java常用容器学习笔记</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/Java%E5%B8%B8%E7%94%A8%E5%AE%B9%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"/>
        <content type="html">&lt;ul&gt;
&lt;li&gt;*##  Collection 接口&lt;br /&gt;
 Collection 接口是 (java.util.Collection) 是 Java 集合类的顶级接口之一，整个集合框架就围绕一组标准接口而设计，其下的 List 和 Map 都是继承自这个接口的。不过 需要注意的是 在源码中 Map 并没有继承 Conllection 接口，&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
百度了一下：&lt;br /&gt;
&lt;em&gt;为什么 map 不继承 collection 接口&lt;/em&gt;&lt;br /&gt;
 1、首先 Map 提供的是键值对映射（即 Key 和 value 的映射），而 collection 提供的是一组数据（并不是键值对映射）。如果 map 继承了 collection 接口，那么所有实现了 map 接口的类到底是用 map 的键值对映射数据还是用 collection 的一组数据呢&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2、map 和 List、set 不同，Map 放的是键值对，list、set 放的是一个个的对象。说到底是因为数据结构不同，数据结构不同，操作就不一样，所以接口是分开的。还是接口分离原则&lt;/p&gt;
&lt;p&gt;当然 Collection 接口提供了一大堆的方法 我挑一些重要的说，当然最好是去看一遍源码，能有更多的体会&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;int size ()  返回集合元素数&lt;br /&gt;
 int hashCode ();  返回 集合的哈希值&lt;br /&gt;
当然还有其他方法 就自己去看源码了&lt;/p&gt;
&lt;hr /&gt;
&lt;h4 id=&#34;说一下什么是哈希值&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#说一下什么是哈希值&#34;&gt;#&lt;/a&gt; 说一下什么是哈希值：&lt;/h4&gt;
&lt;p&gt;hash 是一个函数，该函数中的实现就是一种算法，就是通过一系列的算法来得到一个 hash 值，这个时候，我们就需要知道另一个东西，hash 表，通过 hash 算法得到的 hash 值就在这张 hash 表中，也就是说，hash 表就是所有的 hash 值组成的，有很多种 hash 函数，也就代表着有很多种算法得到 hash 值&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;每个对象都有 hashcode，对象的 hashcode 怎么得来的呢？&lt;/p&gt;
&lt;p&gt;首先一个对象肯定有物理地址&lt;/p&gt;
&lt;p&gt;HashCode 的存在主要是为了查找的快捷性，HashCode 是用来在散列存储结构中确定对象的存储地址的 (后半句说的用 hashcode 来代表对象就是在 hash 表中的位置)&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;为什么哈希会更快？&lt;br /&gt;
比如：我们有一个能存放 1000 个数这样大的内存中，在其中要存放 1000 个不一样的数字，用最笨的方法，就是存一个数字，就遍历一遍，看有没有相同得数，当存了 900 个数字，开始存 901 个数字的时候，就需要跟 900 个数字进行对比，这样就很麻烦，很是消耗时间，用 hashcode 来记录对象的位置，来看一下。hash 表中有 1、2、3、4、5、6、7、8 个位置，存第一个数，hashcode 为 1，该数就放在 hash 表中 1 的位置，存到 100 个数字，hash 表中 8 个位置会有很多数字了，1 中可能有 20 个数字，存 101 个数字时，他先查 hashcode 值对应的位置，假设为 1，那么就有 20 个数字和他的 hashcode 相同，他只需要跟这 20 个数字相比较 (equals)，如果每一个相同，那么就放在 1 这个位置，这样比较的次数就少了很多，实际上 hash 表中有很多位置，这里只是举例只有 8 个，所以比较的次数会让你觉得也挺多的，实际上，如果 hash 表很大，那么比较的次数就很少很少了。  通过对原始方法和使用 hashcode 方法进行对比，我们就知道了 hashcode 的作用，并且为什么要使用 hashcode 了&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&#34;list&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#list&#34;&gt;#&lt;/a&gt; List&lt;/h2&gt;
&lt;p&gt;List 是一个接口 常用的实现有 LinkList 和 ArrayList 和 Vector, 这个 Vertor 后面我们会详细说，&lt;/p&gt;
&lt;p&gt;List 是一个有序的队列，每一个元素都有它的索引。第一个元素的索引值是 0&lt;/p&gt;
&lt;h3 id=&#34;arraylist&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#arraylist&#34;&gt;#&lt;/a&gt; ArrayList&lt;/h3&gt;
&lt;p&gt;ArrayList 是采用数组实现的列表，因此它支持随机访问，不适合频繁删除和插入操作。对于需要经常进行查询的数据建议采用此结构&lt;br /&gt;
 ArrayList 与 java 数组的一个大的区别是 ArrayList 能够自动扩容&lt;br /&gt;
 ArrayList 不支持同步，所谓 不支持同步 就和后面的 Vector 有很大的区别了， ArrayList 是非线程安全的，也就是说，多线程操作 ArrayList 是会出现问题的。&lt;/p&gt;
&lt;hr /&gt;
&lt;h5 id=&#34;下面说说什么是线程安全&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#下面说说什么是线程安全&#34;&gt;#&lt;/a&gt; 下面说说什么是线程安全&lt;/h5&gt;
&lt;p&gt;如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和 单线程运行的结果是一样的，而且其他的 变量的值也和预期的是一样的，就是线程安全的。 反之则是线程不安全&lt;/p&gt;
&lt;h3 id=&#34;linklist&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#linklist&#34;&gt;#&lt;/a&gt; LinkList&lt;/h3&gt;
&lt;p&gt;LinkedList 采用双向链表实现的列表，因此可以被用作队列、堆栈、双端队列；顺序访问高效，随机访问性能较差、适用于需要经常添加和删除的数据。&lt;br /&gt;
LinkedList 不支持同步 也就是 LinkList 也是线程不安全的；&lt;/p&gt;
&lt;h3 id=&#34;vector&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#vector&#34;&gt;#&lt;/a&gt; Vector&lt;/h3&gt;
&lt;p&gt;Vector 用法和 ArrayList 用法很相似，它们的区别在于 Vector 是线程同步的，也就是说 Vertor 是线程安全的，可以在源码中发现，他的方法上都加了 synchronized&lt;br /&gt;
&lt;img data-src=&#34;:/8c883d753bfb4bceb5dcb6535c9bab78&#34; alt=&#34;54fbffae284289b5050edf129b848141.png&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;map&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#map&#34;&gt;#&lt;/a&gt; Map&lt;/h2&gt;
&lt;p&gt;下面来说说 Map map 是由键值组成，也就是 key，value 当然上面在说 Map 不实现 Collection 就说了，这里就不再废话，同样，他也有常用的四个实现类；HashMap,TreeMap ,HashTable&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;hashmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hashmap&#34;&gt;#&lt;/a&gt; HashMap&lt;/h3&gt;
&lt;p&gt;HashMap 允许有 null，不支持同步（支持通过 Collections.synchronizedMap (new Map&amp;lt;…,…&amp;gt;() 实现同步），所以线程不安全。但可以存储大量数据&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;treemap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#treemap&#34;&gt;#&lt;/a&gt; TreeMap&lt;/h3&gt;
&lt;p&gt;基于红黑树的 Map，可以根据 key 的自然排序或者 compareTo 方法排序输出&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;hashtable&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hashtable&#34;&gt;#&lt;/a&gt; HashTable&lt;/h3&gt;
&lt;p&gt;HashTable 的键和值都不允许为空，当然这个是同步的，线程安全，但是只是适合小数据量&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;linkhashmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#linkhashmap&#34;&gt;#&lt;/a&gt; LinkHashMap&lt;/h3&gt;
&lt;p&gt;这个是基于基于双向链表用于维持插入顺序的 HashMap，继承自 HashMap&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;set&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#set&#34;&gt;#&lt;/a&gt; Set&lt;/h3&gt;
&lt;p&gt;Set: 集合，和数学中的集合类似。&lt;br /&gt;
特点：&lt;/p&gt;
&lt;p&gt;确定性：对任一对象都能判定它是否属于某一个集和&lt;br /&gt;
互异性：一个集合中不会存在两个相同（内容相同）的对象&lt;br /&gt;
无序性：集合里面的元素没有顺序&lt;/p&gt;
&lt;h3 id=&#34;hashset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hashset&#34;&gt;#&lt;/a&gt; HashSet&lt;/h3&gt;
&lt;p&gt;基于散列函数的集合，采用 HashMap 实现，可以容纳 null 元素，不支持同步（可以通过 Collections.synchronizedSet (new HashSet&amp;lt;…&amp;gt;() 来使它同步）&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&#34;treeset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#treeset&#34;&gt;#&lt;/a&gt; TreeSet&lt;/h3&gt;
&lt;p&gt;基于树结构的集和，印次支持排序，不能容纳 null 元素，同样不支持同步&lt;/p&gt;
&lt;h3 id=&#34;hashlinkedset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hashlinkedset&#34;&gt;#&lt;/a&gt; HashLinkedSet&lt;/h3&gt;
&lt;p&gt;继承 HashSet ，基于散列函数和双向链表的集和，可以容纳 null 元素，通过双向链表维护了插入顺序，从而支持排序，但不支持同步（可以通过 Collections.synchronizedSet (new HashSet&amp;lt;…&amp;gt;() 来使它同步）&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#总结&#34;&gt;#&lt;/a&gt; 总结&lt;/h1&gt;
&lt;p&gt;在以上的容器中，只有 Vector 和 HashTable  提供了同步 当然这是 List 和 Map 下的&lt;/p&gt;
&lt;h2 id=&#34;分类&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#分类&#34;&gt;#&lt;/a&gt; 分类：&lt;/h2&gt;
&lt;p&gt;１）Collection：一个独立元素的序列，这些元素都服从一条或者多条规则。 List 必须按照插入的顺序保存元素，而 set 不能有重复的元素。Queue 按照排队规则来确定对象产生的顺序（通常与它们被插入的顺序相同）。&lt;/p&gt;
&lt;p&gt;2）Map：一组成对的 “键值对” 对象，允许你使用键来查找值。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;:/882871cdf49e4d36a2084ef4805d999b&#34; alt=&#34;6487b08e90a82dc2b1544cc20fdbd219.png&#34; /&gt;&lt;/p&gt;
</content>
        <category term="java" scheme="https://zhai-xing.github.io/mb-blog/categories/java/" />
        <category term="数据结构与算法" scheme="https://zhai-xing.github.io/mb-blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" />
        <updated>2023-03-07T16:12:31.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/%E6%9C%80%E5%B0%8F%E6%A0%88</id>
        <title>最小栈</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/%E6%9C%80%E5%B0%8F%E6%A0%88"/>
        <content type="html">&lt;h3 id=&#34;最小栈&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#最小栈&#34;&gt;#&lt;/a&gt; 最小栈&lt;/h3&gt;
&lt;h5 id=&#34;题目需求&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#题目需求&#34;&gt;#&lt;/a&gt; 题目需求：&lt;/h5&gt;
&lt;p&gt;实现一个这样的栈，这个栈除了可以进行普通的 push、pop 操作以外，还可以进行 getMin 的操作，getMin 方法被调用后，会返回当前栈的最小值。栈里面存放的都是 int 整数，&lt;br /&gt;
力扣题目：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9taW4tc3RhY2sv&#34;&gt;实现一个最小栈&lt;/span&gt;&lt;/p&gt;
&lt;h5 id=&#34;暴力版本实现&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#暴力版本实现&#34;&gt;#&lt;/a&gt; 暴力版本实现&lt;/h5&gt;
&lt;p&gt;时间复杂度为 O (n)；空间复杂度为 O (1)&lt;br /&gt;
 采用一个指针来指向最小元素下标，每次出栈都要判断出栈元素是否是当前最小，如果是就要去遍历，更新最小指针，&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class MinStack &amp;#123;
    int[] nums;
    int minIndex;
    int index;

    /** initialize your data structure here. */
    public MinStack() &amp;#123;
        this.nums=new int[20000];
        this.index=0;
        this.minIndex=-1;
    &amp;#125;    
    public void push(int x) &amp;#123;
        nums[index]=x;
        index++;
        if(minIndex==-1)&amp;#123;
            minIndex=0;
        &amp;#125;else if(x&amp;lt;nums[minIndex])&amp;#123;
            minIndex=index-1;
        &amp;#125;
    &amp;#125;
    
    public void pop() &amp;#123;
        index--;
        if(index==minIndex)&amp;#123;
            minIndex=0;
            for(int i=0;i&amp;lt;index;i++)&amp;#123;
                if(nums[i]&amp;lt;=nums[minIndex])&amp;#123;
                    minIndex=i;
                &amp;#125;
            &amp;#125;
        &amp;#125;
        
    &amp;#125;
    
    public int top() &amp;#123;
        return nums[index-1];
    &amp;#125;
    
    public int min() &amp;#123;
        return nums[minIndex];
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;辅助栈实现&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#辅助栈实现&#34;&gt;#&lt;/a&gt; 辅助栈实现&lt;/h5&gt;
&lt;p&gt;采用一个辅助栈来实现，其时间复杂度为 O (1), 空间复杂度为 O (n)&lt;br /&gt;
 有两个栈 s1 和 s2，s1 是目标栈，s2 是辅助栈，用来存放最小值。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每次 getMin 的时候，直接从 s2 栈顶获取即可&lt;/li&gt;
&lt;li&gt;每次入栈，s1 直接入栈，s2 则需要判断，若当前入栈元素小于 s2 的栈顶元素，则直接入栈，若当前元素大于等于 s2 的栈顶元素，则把 s2 的栈顶元素值，入栈一次。&lt;/li&gt;
&lt;li&gt;每次出栈，s1,s2 都直接弹出即可&lt;/li&gt;
&lt;li&gt;需要注意，若首次入栈，也可以当 s2 为空栈的时候，直接将当前元素入栈&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;class MinStack &amp;#123;
    Stack&amp;lt;Integer&amp;gt; s1;
    Stack&amp;lt;Integer&amp;gt; s2;
    /** initialize your data structure here. */
    public MinStack() &amp;#123;
        this.s1=new Stack&amp;lt;Integer&amp;gt;();
        this.s2=new Stack&amp;lt;Integer&amp;gt;();
    &amp;#125;    
    public void push(int x) &amp;#123;
        s1.push(x);
        if(s2.empty())&amp;#123;
            s2.push(x);
        &amp;#125;else&amp;#123;
            if(x&amp;lt;s2.peek())&amp;#123;
            s2.push(x);
            &amp;#125;else&amp;#123;
                s2.push(s2.peek());
            &amp;#125;
        &amp;#125;
    &amp;#125;
    
    public void pop() &amp;#123;
        s1.pop();
        s2.pop();
    &amp;#125;
    
    public int top() &amp;#123;
        return s1.peek();
    &amp;#125;
    
    public int min() &amp;#123;
        return s2.peek();
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;使用存差值实现最优&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#使用存差值实现最优&#34;&gt;#&lt;/a&gt; 使用存差值实现 (最优)&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;public class MinStack &amp;#123;

    private Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;Integer&amp;gt;();
    private int min;

    public void push(int x) &amp;#123;
        if (stack.isEmpty()) &amp;#123;
            min = x;
            stack.push(0);
        &amp;#125; else &amp;#123;
            // 计算差值
            int compare = x - min;
            stack.push(compare);
            // 如果差值小于0，显然 x 成为最小值，否则最小值不变
            min = compare &amp;lt; 0 ? x : min;
        &amp;#125;
    &amp;#125;

    public void pop() &amp;#123;
        int top = stack.peek();
        // 如果top小于0，显然最小值也一并会被删除，此时更新最小值
        
        min = top &amp;lt; 0 ? (min - top) : min;
        stack.pop();
    &amp;#125;

    public int getMin() &amp;#123;
        return min;
    &amp;#125;
 &amp;#125;
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="剑指offer" scheme="https://zhai-xing.github.io/mb-blog/categories/%E5%89%91%E6%8C%87offer/" />
        <category term="数据结构与算法" scheme="https://zhai-xing.github.io/mb-blog/categories/%E5%89%91%E6%8C%87offer/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" />
        <category term="最小栈" scheme="https://zhai-xing.github.io/mb-blog/tags/%E6%9C%80%E5%B0%8F%E6%A0%88/" />
        <category term="栈" scheme="https://zhai-xing.github.io/mb-blog/tags/%E6%A0%88/" />
        <category term="数据结构" scheme="https://zhai-xing.github.io/mb-blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" />
        <updated>2023-02-09T14:41:55.000Z</updated>
    </entry>
    <entry>
        <id>https://zhai-xing.github.io/mb-blog/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE</id>
        <title>二分查找</title>
        <link rel="alternate" href="https://zhai-xing.github.io/mb-blog/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE"/>
        <content type="html">&lt;h3 id=&#34;二分查找&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二分查找&#34;&gt;#&lt;/a&gt; 二分查找&lt;/h3&gt;
&lt;h4 id=&#34;1-左闭右闭区间&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-左闭右闭区间&#34;&gt;#&lt;/a&gt; 1、左闭右闭区间&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;public static int efzbyb(int[] nums,int target)&amp;#123;
        int L=0;
        int R=nums.length-1;
        int mid;
        //区间是左闭右闭 left==right的时候是一个合法的区间，所以是&amp;lt;=
        while(L&amp;lt;=R)&amp;#123;
            mid=(L+R)/2;
            if(nums[mid]&amp;lt;target)&amp;#123;
                L=mid+1;// 因为是左闭右闭， mid处的值，已经明确不等于target 所以要+1
            &amp;#125;else if(nums[mid]&amp;gt;target)&amp;#123;
                R=mid-1;
            &amp;#125;else&amp;#123;
                return mid;
            &amp;#125;
        &amp;#125;
        //未找到返回-1;
        return -1;
    &amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-左闭右开区间&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-左闭右开区间&#34;&gt;#&lt;/a&gt; 2、左闭右开区间&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;public static  int efzbyk(int[] nums,int target)&amp;#123;
        int L=0;
        int R=nums.length; //因为是左闭右开，所以右边是可以取不到的；
        int mid;
        //因为是左闭右开，所以L=R是一个非法的区间，R可能是没有值的;
        while(L&amp;lt;R)&amp;#123;
            mid=(L+R)/2;
            if(nums[mid]&amp;lt;target)&amp;#123;
                L=mid+1; //因为是左区间，mid处的值已经确定不等于target,所以需要+1才可用
            &amp;#125;else if(nums[mid]&amp;gt;target)&amp;#123;
                R=mid; // 因为是右边是开区间，所以是可用直接使用已经用过的值，
            &amp;#125;else&amp;#123;
                return mid;
            &amp;#125;
        &amp;#125;
        return -1;
    &amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;二分查找左右边界&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二分查找左右边界&#34;&gt;#&lt;/a&gt; 二分查找左右边界&lt;/h3&gt;
&lt;h4 id=&#34;1-查找左边界&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-查找左边界&#34;&gt;#&lt;/a&gt; 1、查找左边界&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;//寻址第一次出现的位置
    public int first(int[] nums,int target)&amp;#123;
        int l=0;
        int r=nums.length-1;
        int mid;
        while(l&amp;lt;=r)&amp;#123;
            mid=(l+r)/2;
            if(nums[mid]&amp;lt;target)&amp;#123;
                l=mid+1;
            &amp;#125;else&amp;#123;
                r=mid-1;
            &amp;#125;
        &amp;#125;
             //当找不到的时候，边界可能会超出;
        if(l==nums.length)&amp;#123;
            return -1;
        &amp;#125;
        //找到值不满足条件；
        if(nums[l]!=target)&amp;#123;
            return -1;
        &amp;#125;
        
        return l;
    &amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-查找右边界&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-查找右边界&#34;&gt;#&lt;/a&gt; 2、查找右边界&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;//寻址最后一次出现的位置
    public int last(int[] num,int target)&amp;#123;
        int l=0;
        int r=num.length-1;
        int mid;
        while(l&amp;lt;=r)&amp;#123;
            mid=(l+r+1)/2;
            if(num[mid]&amp;gt;target)&amp;#123;
                r=mid-1;
            &amp;#125;
            else&amp;#123;
                l=mid+1;
            &amp;#125;
        &amp;#125;
        return r;
    &amp;#125;
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="代码随想录学习" scheme="https://zhai-xing.github.io/mb-blog/categories/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E5%AD%A6%E4%B9%A0/" />
        <category term="数据结构与算法" scheme="https://zhai-xing.github.io/mb-blog/categories/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" />
        <category term="二分查找" scheme="https://zhai-xing.github.io/mb-blog/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" />
        <category term="数组" scheme="https://zhai-xing.github.io/mb-blog/tags/%E6%95%B0%E7%BB%84/" />
        <category term="算法" scheme="https://zhai-xing.github.io/mb-blog/tags/%E7%AE%97%E6%B3%95/" />
        <updated>2023-02-09T14:38:24.000Z</updated>
    </entry>
</feed>
